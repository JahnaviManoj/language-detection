{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zt0uT-7V9iH_"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip language-training.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPMXsncZGZ_V",
        "outputId": "45a99726-6112-4e2a-f5ca-4345a0e15667"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  language-training.zip\n",
            "   creating: language-training/Czech/\n",
            "  inflating: language-training/Czech/23_cm_her101  \n",
            "  inflating: language-training/Czech/bestiary  \n",
            "  inflating: language-training/Czech/character  \n",
            "  inflating: language-training/Czech/cn_jaskier07  \n",
            "  inflating: language-training/Czech/cn_julian01  \n",
            "  inflating: language-training/Czech/cn_kalkstein10  \n",
            "  inflating: language-training/Czech/cn_lady01  \n",
            "  inflating: language-training/Czech/cn_leuvaarden10  \n",
            "  inflating: language-training/Czech/cn_raymond05  \n",
            "  inflating: language-training/Czech/cn_shani19  \n",
            "  inflating: language-training/Czech/cn_talar01  \n",
            "  inflating: language-training/Czech/cn_triss01  \n",
            "  inflating: language-training/Czech/cn_vincent02  \n",
            "  inflating: language-training/Czech/tutorial  \n",
            "   creating: language-training/English/\n",
            "  inflating: language-training/English/23_cm_her101  \n",
            "  inflating: language-training/English/bestiary  \n",
            "  inflating: language-training/English/character  \n",
            "  inflating: language-training/English/cn_jaskier07  \n",
            "  inflating: language-training/English/cn_julian01  \n",
            "  inflating: language-training/English/cn_kalkstein10  \n",
            "  inflating: language-training/English/cn_lady01  \n",
            "  inflating: language-training/English/cn_leuvaarden10  \n",
            "  inflating: language-training/English/cn_raymond05  \n",
            "  inflating: language-training/English/cn_shani19  \n",
            "  inflating: language-training/English/cn_talar01  \n",
            "  inflating: language-training/English/cn_triss01  \n",
            "  inflating: language-training/English/cn_vincent02  \n",
            "  inflating: language-training/English/tutorial  \n",
            "   creating: language-training/French/\n",
            "  inflating: language-training/French/23_cm_her101  \n",
            "  inflating: language-training/French/bestiary  \n",
            "  inflating: language-training/French/character  \n",
            "  inflating: language-training/French/cn_jaskier07  \n",
            "  inflating: language-training/French/cn_julian01  \n",
            "  inflating: language-training/French/cn_kalkstein10  \n",
            "  inflating: language-training/French/cn_lady01  \n",
            "  inflating: language-training/French/cn_leuvaarden10  \n",
            "  inflating: language-training/French/cn_raymond05  \n",
            "  inflating: language-training/French/cn_shani19  \n",
            "  inflating: language-training/French/cn_talar01  \n",
            "  inflating: language-training/French/cn_triss01  \n",
            "  inflating: language-training/French/cn_vincent02  \n",
            "  inflating: language-training/French/tutorial  \n",
            "   creating: language-training/German/\n",
            "  inflating: language-training/German/23_cm_her101  \n",
            "  inflating: language-training/German/bestiary  \n",
            "  inflating: language-training/German/character  \n",
            "  inflating: language-training/German/cn_jaskier07  \n",
            "  inflating: language-training/German/cn_julian01  \n",
            "  inflating: language-training/German/cn_kalkstein10  \n",
            "  inflating: language-training/German/cn_lady01  \n",
            "  inflating: language-training/German/cn_leuvaarden10  \n",
            "  inflating: language-training/German/cn_raymond05  \n",
            "  inflating: language-training/German/cn_shani19  \n",
            "  inflating: language-training/German/cn_talar01  \n",
            "  inflating: language-training/German/cn_triss01  \n",
            "  inflating: language-training/German/cn_vincent02  \n",
            "  inflating: language-training/German/tutorial  \n",
            "   creating: language-training/Hungarian/\n",
            "  inflating: language-training/Hungarian/23_cm_her101  \n",
            "  inflating: language-training/Hungarian/bestiary  \n",
            "  inflating: language-training/Hungarian/character  \n",
            "  inflating: language-training/Hungarian/cn_jaskier07  \n",
            "  inflating: language-training/Hungarian/cn_julian01  \n",
            "  inflating: language-training/Hungarian/cn_kalkstein10  \n",
            "  inflating: language-training/Hungarian/cn_lady01  \n",
            "  inflating: language-training/Hungarian/cn_leuvaarden10  \n",
            "  inflating: language-training/Hungarian/cn_raymond05  \n",
            "  inflating: language-training/Hungarian/cn_shani19  \n",
            "  inflating: language-training/Hungarian/cn_talar01  \n",
            "  inflating: language-training/Hungarian/cn_triss01  \n",
            "  inflating: language-training/Hungarian/cn_vincent02  \n",
            "  inflating: language-training/Hungarian/tutorial  \n",
            "   creating: language-training/Italian/\n",
            "  inflating: language-training/Italian/23_cm_her101  \n",
            "  inflating: language-training/Italian/bestiary  \n",
            "  inflating: language-training/Italian/character  \n",
            "  inflating: language-training/Italian/cn_jaskier07  \n",
            "  inflating: language-training/Italian/cn_julian01  \n",
            "  inflating: language-training/Italian/cn_kalkstein10  \n",
            "  inflating: language-training/Italian/cn_lady01  \n",
            "  inflating: language-training/Italian/cn_leuvaarden10  \n",
            "  inflating: language-training/Italian/cn_raymond05  \n",
            "  inflating: language-training/Italian/cn_shani19  \n",
            "  inflating: language-training/Italian/cn_talar01  \n",
            "  inflating: language-training/Italian/cn_triss01  \n",
            "  inflating: language-training/Italian/cn_vincent02  \n",
            "  inflating: language-training/Italian/tutorial  \n",
            "   creating: language-training/Polish/\n",
            "  inflating: language-training/Polish/23_cm_her101  \n",
            "  inflating: language-training/Polish/bestiary  \n",
            "  inflating: language-training/Polish/character  \n",
            "  inflating: language-training/Polish/cn_jaskier07  \n",
            "  inflating: language-training/Polish/cn_julian01  \n",
            "  inflating: language-training/Polish/cn_kalkstein10  \n",
            "  inflating: language-training/Polish/cn_lady01  \n",
            "  inflating: language-training/Polish/cn_leuvaarden10  \n",
            "  inflating: language-training/Polish/cn_raymond05  \n",
            "  inflating: language-training/Polish/cn_shani19  \n",
            "  inflating: language-training/Polish/cn_talar01  \n",
            "  inflating: language-training/Polish/cn_triss01  \n",
            "  inflating: language-training/Polish/cn_vincent02  \n",
            "  inflating: language-training/Polish/tutorial  \n",
            "   creating: language-training/Russian/\n",
            "  inflating: language-training/Russian/23_cm_her101  \n",
            "  inflating: language-training/Russian/bestiary  \n",
            "  inflating: language-training/Russian/character  \n",
            "  inflating: language-training/Russian/cn_jaskier07  \n",
            "  inflating: language-training/Russian/cn_julian01  \n",
            "  inflating: language-training/Russian/cn_kalkstein10  \n",
            "  inflating: language-training/Russian/cn_lady01  \n",
            "  inflating: language-training/Russian/cn_leuvaarden10  \n",
            "  inflating: language-training/Russian/cn_raymond05  \n",
            "  inflating: language-training/Russian/cn_shani19  \n",
            "  inflating: language-training/Russian/cn_talar01  \n",
            "  inflating: language-training/Russian/cn_triss01  \n",
            "  inflating: language-training/Russian/cn_vincent02  \n",
            "  inflating: language-training/Russian/tutorial  \n",
            "   creating: language-training/Spanish/\n",
            "  inflating: language-training/Spanish/23_cm_her101  \n",
            "  inflating: language-training/Spanish/bestiary  \n",
            "  inflating: language-training/Spanish/character  \n",
            "  inflating: language-training/Spanish/cn_jaskier07  \n",
            "  inflating: language-training/Spanish/cn_julian01  \n",
            "  inflating: language-training/Spanish/cn_kalkstein10  \n",
            "  inflating: language-training/Spanish/cn_lady01  \n",
            "  inflating: language-training/Spanish/cn_leuvaarden10  \n",
            "  inflating: language-training/Spanish/cn_raymond05  \n",
            "  inflating: language-training/Spanish/cn_shani19  \n",
            "  inflating: language-training/Spanish/cn_talar01  \n",
            "  inflating: language-training/Spanish/cn_triss01  \n",
            "  inflating: language-training/Spanish/cn_vincent02  \n",
            "  inflating: language-training/Spanish/tutorial  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOADING TRAINING DATA"
      ],
      "metadata": {
        "id": "js-luyt2XeE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading training data from folder for given language"
      ],
      "metadata": {
        "id": "kNJ31nZoHQ9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_training_data(lang):\n",
        "  files = ['23_cm_her101', 'bestiary', 'character', 'cn_jaskier07', 'cn_julian01', 'cn_kalkstein10', 'cn_lady01', 'cn_leuvaarden10', 'cn_raymond05', 'cn_shani19', 'cn_talar01', 'cn_triss01', 'cn_vincent02', 'tutorial']\n",
        "\n",
        "  text = []\n",
        "  for f in files:\n",
        "    para = open('language-training/' + lang + '/' + f, 'r', encoding=\"utf8\").readlines()\n",
        "    for line in para:\n",
        "      text.append(line)\n",
        "  return text"
      ],
      "metadata": {
        "id": "uYkJpY0EHa40"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data is an array of paragraphs. for example here is eng_text[3]"
      ],
      "metadata": {
        "id": "rbpxMedJH2GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_text = load_training_data('English')\n",
        "eng_text[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "arSadJc6H7WU",
        "outputId": "47b41932-0bf7-4e7d-c440-7cb47304fd01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I see you are a witcher. Has a villager finally sought to do something about the midday ladies?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPROCESSING TRAINING DATA"
      ],
      "metadata": {
        "id": "LY5zRRLfXiRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(text):\n",
        "  ret_words = []\n",
        "  for sentence in text:\n",
        "    words = sentence.split()\n",
        "    for word in words:\n",
        "      cleaned_word = re.sub(r'[\\W]', '', word)\n",
        "      if cleaned_word != '':\n",
        "        ret_words.append(cleaned_word.lower())\n",
        "  return ret_words"
      ],
      "metadata": {
        "id": "G89BQmhZXl-d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the english text. For example here is pre-process for [\"'I see you are a witcher. Has a villager finally sought to do something about the midday ladies?\\n'\"]. notice stripping of special characters such as ?"
      ],
      "metadata": {
        "id": "hRBN5iUoZ61f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_words = preprocess_data([\"'I see you are a witcher. Has a villager finally sought to do something about the midday ladies?\\n'\"])\n",
        "eng_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DbNs9fwY8tY",
        "outputId": "ee5ad3e8-3762-43fa-c4af-1cf68d3da180"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'see',\n",
              " 'you',\n",
              " 'are',\n",
              " 'a',\n",
              " 'witcher',\n",
              " 'has',\n",
              " 'a',\n",
              " 'villager',\n",
              " 'finally',\n",
              " 'sought',\n",
              " 'to',\n",
              " 'do',\n",
              " 'something',\n",
              " 'about',\n",
              " 'the',\n",
              " 'midday',\n",
              " 'ladies']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COUNTING NUMBER OF TIMES A TRIGRAM WAS OBSERVED"
      ],
      "metadata": {
        "id": "z7E05Cpoa83P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through this function, we get counts of each trigram. Now for a given text in a language, we can create an n-dimensional vector where each trigram corresponds to a dimnension and the number of times a trigram was observed is the value for that dimension."
      ],
      "metadata": {
        "id": "uIKpc5EVTIOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_trigram_vector(words):\n",
        "  trigram_vector = {}\n",
        "  for w in words:\n",
        "    ch = '.' + w + '.'\n",
        "    for c1, c2, c3 in zip(ch, ch[1:], ch[2:]):\n",
        "      trigram_vector[c1+c2+c3] = trigram_vector.get(c1+c2+c3, 0) + 1\n",
        "  return trigram_vector"
      ],
      "metadata": {
        "id": "0CCbU3goa_-v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, creating trigram counts for the english language from the english words"
      ],
      "metadata": {
        "id": "eO5k-A_IcC-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_count = create_trigram_vector(eng_words)\n",
        "eng_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKbaA7urbXXY",
        "outputId": "f4986afc-b1ce-440d-b321-002cc3f81468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.i.': 690,\n",
              " '.do': 339,\n",
              " 'don': 131,\n",
              " 'ont': 177,\n",
              " 'nt.': 508,\n",
              " '.ha': 436,\n",
              " 'hav': 218,\n",
              " 'ave': 328,\n",
              " 've.': 535,\n",
              " '.ti': 81,\n",
              " 'tim': 108,\n",
              " 'ime': 111,\n",
              " 'me.': 409,\n",
              " '.no': 364,\n",
              " 'now': 258,\n",
              " 'ow.': 336,\n",
              " '.wh': 445,\n",
              " 'who': 88,\n",
              " 'ho.': 70,\n",
              " '.is': 323,\n",
              " 'is.': 534,\n",
              " '.it': 388,\n",
              " 'it.': 347,\n",
              " '.th': 2579,\n",
              " 'tha': 381,\n",
              " 'hat': 493,\n",
              " 'at.': 583,\n",
              " 'the': 1990,\n",
              " 'he.': 1441,\n",
              " '.go': 150,\n",
              " 'god': 26,\n",
              " 'ods': 17,\n",
              " 'ds.': 161,\n",
              " '.le': 185,\n",
              " 'led': 107,\n",
              " 'ed.': 865,\n",
              " '.to': 1046,\n",
              " 'to.': 959,\n",
              " '.me': 307,\n",
              " '.gr': 136,\n",
              " 'gre': 56,\n",
              " 'ree': 53,\n",
              " 'eet': 18,\n",
              " 'eti': 26,\n",
              " 'tin': 131,\n",
              " 'ing': 886,\n",
              " 'ngs': 52,\n",
              " 'gs.': 57,\n",
              " '.my': 180,\n",
              " 'my.': 217,\n",
              " '.na': 39,\n",
              " 'nam': 18,\n",
              " 'ame': 50,\n",
              " '.ge': 191,\n",
              " 'ger': 138,\n",
              " 'era': 121,\n",
              " 'ral': 105,\n",
              " 'alt': 111,\n",
              " 'lt.': 117,\n",
              " '.se': 312,\n",
              " 'see': 105,\n",
              " 'ee.': 95,\n",
              " '.yo': 1072,\n",
              " 'you': 1086,\n",
              " 'ou.': 745,\n",
              " '.ar': 327,\n",
              " 'are': 364,\n",
              " 're.': 822,\n",
              " '.a.': 585,\n",
              " '.wi': 451,\n",
              " 'wit': 308,\n",
              " 'itc': 116,\n",
              " 'tch': 131,\n",
              " 'che': 209,\n",
              " 'her': 468,\n",
              " 'er.': 762,\n",
              " 'has': 67,\n",
              " 'as.': 304,\n",
              " '.vi': 112,\n",
              " 'vil': 18,\n",
              " 'ill': 278,\n",
              " 'lla': 22,\n",
              " 'lag': 15,\n",
              " 'age': 81,\n",
              " '.fi': 224,\n",
              " 'fin': 104,\n",
              " 'ina': 94,\n",
              " 'nal': 48,\n",
              " 'all': 274,\n",
              " 'lly': 84,\n",
              " 'ly.': 369,\n",
              " '.so': 351,\n",
              " 'sou': 43,\n",
              " 'oug': 96,\n",
              " 'ugh': 104,\n",
              " 'ght': 234,\n",
              " 'ht.': 165,\n",
              " 'do.': 139,\n",
              " 'som': 169,\n",
              " 'ome': 249,\n",
              " 'met': 89,\n",
              " 'eth': 74,\n",
              " 'thi': 383,\n",
              " 'hin': 262,\n",
              " 'ng.': 893,\n",
              " '.ab': 201,\n",
              " 'abo': 141,\n",
              " 'bou': 130,\n",
              " 'out': 231,\n",
              " 'ut.': 387,\n",
              " '.mi': 133,\n",
              " 'mid': 17,\n",
              " 'idd': 23,\n",
              " 'dda': 21,\n",
              " 'day': 25,\n",
              " 'ay.': 156,\n",
              " '.la': 129,\n",
              " 'lad': 72,\n",
              " 'adi': 12,\n",
              " 'die': 36,\n",
              " 'ies': 110,\n",
              " 'es.': 669,\n",
              " '.mo': 245,\n",
              " 'mor': 139,\n",
              " 'ore': 154,\n",
              " '.or': 131,\n",
              " 'or.': 378,\n",
              " 'les': 79,\n",
              " 'ess': 161,\n",
              " 'ss.': 153,\n",
              " 'lea': 93,\n",
              " 'ead': 101,\n",
              " 'ad.': 131,\n",
              " '.li': 185,\n",
              " 'lif': 32,\n",
              " 'ife': 30,\n",
              " 'fe.': 32,\n",
              " '.of': 589,\n",
              " 'of.': 552,\n",
              " '.he': 403,\n",
              " 'erm': 16,\n",
              " 'rmi': 14,\n",
              " 'mit': 19,\n",
              " 'ere': 339,\n",
              " 'ith': 213,\n",
              " 'th.': 267,\n",
              " '.fe': 83,\n",
              " 'few': 18,\n",
              " 'ew.': 55,\n",
              " '.lu': 17,\n",
              " 'lux': 3,\n",
              " 'uxu': 3,\n",
              " 'xur': 3,\n",
              " 'uri': 32,\n",
              " 'rie': 70,\n",
              " '.bu': 223,\n",
              " 'but': 160,\n",
              " '.ma': 277,\n",
              " 'mak': 37,\n",
              " 'ake': 118,\n",
              " 'ke.': 172,\n",
              " 'our': 357,\n",
              " 'urs': 67,\n",
              " 'rse': 47,\n",
              " 'sel': 54,\n",
              " 'elf': 36,\n",
              " 'lf.': 40,\n",
              " '.at': 160,\n",
              " '.ho': 166,\n",
              " 'hom': 6,\n",
              " 'han': 142,\n",
              " 'ank': 34,\n",
              " 'nk.': 81,\n",
              " '.by': 99,\n",
              " 'by.': 98,\n",
              " '.wa': 282,\n",
              " 'way': 73,\n",
              " '.sp': 115,\n",
              " 'spe': 109,\n",
              " 'pea': 86,\n",
              " 'eak': 39,\n",
              " 'ak.': 30,\n",
              " '.as': 150,\n",
              " 'ass': 59,\n",
              " 'ssu': 19,\n",
              " 'sum': 26,\n",
              " 'ume': 15,\n",
              " '.we': 259,\n",
              " 'wel': 87,\n",
              " 'ell': 185,\n",
              " 'll.': 512,\n",
              " '.ed': 6,\n",
              " 'edu': 6,\n",
              " 'duc': 11,\n",
              " 'uca': 2,\n",
              " 'cat': 27,\n",
              " 'ate': 198,\n",
              " 'ted': 159,\n",
              " '.co': 388,\n",
              " 'cor': 26,\n",
              " 'orr': 28,\n",
              " 'rre': 27,\n",
              " 'rec': 53,\n",
              " 'ect': 169,\n",
              " 'ct.': 70,\n",
              " 'pen': 48,\n",
              " 'ent': 341,\n",
              " 'mos': 37,\n",
              " 'ost': 77,\n",
              " 'st.': 322,\n",
              " 'ser': 49,\n",
              " 'erv': 42,\n",
              " 'rvi': 9,\n",
              " 'vin': 74,\n",
              " '.ki': 103,\n",
              " 'kin': 133,\n",
              " '.fo': 355,\n",
              " 'fol': 14,\n",
              " 'olt': 5,\n",
              " 'lte': 5,\n",
              " 'tes': 48,\n",
              " 'est': 201,\n",
              " '.di': 200,\n",
              " 'dip': 1,\n",
              " 'ipl': 4,\n",
              " 'plo': 12,\n",
              " 'lom': 1,\n",
              " 'oma': 21,\n",
              " 'mat': 59,\n",
              " '.wo': 197,\n",
              " 'wou': 48,\n",
              " 'oul': 177,\n",
              " 'uld': 112,\n",
              " 'ld.': 202,\n",
              " '.be': 454,\n",
              " 'be.': 228,\n",
              " 'for': 366,\n",
              " 'orw': 3,\n",
              " 'rwa': 15,\n",
              " 'war': 62,\n",
              " 'ard': 133,\n",
              " 'rd.': 112,\n",
              " 'ask': 25,\n",
              " 'sk.': 26,\n",
              " 'wha': 155,\n",
              " '.in': 644,\n",
              " 'ins': 96,\n",
              " 'nsp': 11,\n",
              " 'spi': 35,\n",
              " 'pir': 29,\n",
              " 'ire': 91,\n",
              " 'red': 97,\n",
              " 'eek': 7,\n",
              " 'ek.': 2,\n",
              " 'iso': 41,\n",
              " 'sol': 26,\n",
              " 'ola': 6,\n",
              " 'lat': 47,\n",
              " 'ati': 165,\n",
              " 'tio': 231,\n",
              " 'ion': 304,\n",
              " 'on.': 479,\n",
              " '.ou': 110,\n",
              " 'cou': 73,\n",
              " 'se.': 285,\n",
              " '.ca': 378,\n",
              " 'can': 216,\n",
              " 'an.': 376,\n",
              " '.on': 324,\n",
              " 'onl': 65,\n",
              " 'nly': 71,\n",
              " '.sa': 181,\n",
              " 'say': 33,\n",
              " 'aba': 12,\n",
              " 'ban': 29,\n",
              " 'and': 908,\n",
              " 'ndo': 12,\n",
              " 'one': 261,\n",
              " 'ned': 96,\n",
              " '.ci': 27,\n",
              " 'cit': 27,\n",
              " 'ity': 179,\n",
              " 'ty.': 204,\n",
              " 'whe': 122,\n",
              " 'hen': 126,\n",
              " 'en.': 335,\n",
              " 'ady': 58,\n",
              " 'dy.': 81,\n",
              " 'lak': 17,\n",
              " '.su': 197,\n",
              " 'umm': 15,\n",
              " 'mmo': 22,\n",
              " 'mon': 138,\n",
              " 'rve': 36,\n",
              " 'get': 111,\n",
              " 'et.': 191,\n",
              " '.bo': 114,\n",
              " 'bor': 25,\n",
              " 'int': 129,\n",
              " 'nte': 120,\n",
              " 'tel': 84,\n",
              " 'lli': 43,\n",
              " 'lig': 37,\n",
              " 'ige': 16,\n",
              " 'gen': 41,\n",
              " '.pe': 134,\n",
              " 'peo': 67,\n",
              " 'eop': 67,\n",
              " 'opl': 70,\n",
              " 'ple': 125,\n",
              " 'le.': 301,\n",
              " '.ne': 192,\n",
              " 'nev': 15,\n",
              " 'eve': 187,\n",
              " 'ver': 250,\n",
              " '.an': 945,\n",
              " 'nd.': 997,\n",
              " '.br': 86,\n",
              " 'bro': 26,\n",
              " 'rou': 109,\n",
              " 'lib': 2,\n",
              " 'ibr': 5,\n",
              " 'bra': 22,\n",
              " 'rar': 23,\n",
              " 'ary': 22,\n",
              " 'ry.': 179,\n",
              " 'wen': 11,\n",
              " 'nto': 50,\n",
              " '.ex': 93,\n",
              " 'exi': 5,\n",
              " 'xil': 4,\n",
              " 'ile': 42,\n",
              " '.us': 99,\n",
              " 'use': 140,\n",
              " '.kn': 256,\n",
              " 'kno': 239,\n",
              " 'owl': 27,\n",
              " 'wle': 25,\n",
              " 'edg': 29,\n",
              " 'dge': 34,\n",
              " 'ge.': 109,\n",
              " '.dr': 75,\n",
              " 'dra': 80,\n",
              " 'raw': 12,\n",
              " 'aw.': 24,\n",
              " '.fr': 142,\n",
              " 'fro': 96,\n",
              " 'rom': 106,\n",
              " 'om.': 110,\n",
              " 'boo': 26,\n",
              " 'ook': 67,\n",
              " 'oks': 19,\n",
              " 'ks.': 76,\n",
              " 'erb': 10,\n",
              " 'rbs': 4,\n",
              " 'bs.': 12,\n",
              " '.pr': 214,\n",
              " 'pre': 74,\n",
              " 'rep': 28,\n",
              " 'epa': 13,\n",
              " 'par': 41,\n",
              " '.po': 148,\n",
              " 'pot': 8,\n",
              " 'oti': 22,\n",
              " 'ons': 176,\n",
              " 'ns.': 211,\n",
              " '.mu': 93,\n",
              " 'mur': 6,\n",
              " 'urk': 4,\n",
              " 'rky': 2,\n",
              " 'ky.': 15,\n",
              " 'wat': 29,\n",
              " 'ter': 329,\n",
              " 'ers': 262,\n",
              " 'rs.': 280,\n",
              " 'pro': 132,\n",
              " 'rov': 28,\n",
              " 'ovi': 12,\n",
              " 'vid': 16,\n",
              " 'ide': 169,\n",
              " 'de.': 68,\n",
              " 'foo': 14,\n",
              " 'ood': 86,\n",
              " 'od.': 76,\n",
              " 'in.': 499,\n",
              " 'exc': 17,\n",
              " 'xch': 3,\n",
              " 'cha': 86,\n",
              " 'ang': 60,\n",
              " 'nge': 81,\n",
              " 'ur.': 224,\n",
              " '.pl': 98,\n",
              " 'eas': 114,\n",
              " 'ase': 48,\n",
              " 'exa': 15,\n",
              " 'xam': 7,\n",
              " 'ami': 20,\n",
              " 'min': 78,\n",
              " 'ine': 83,\n",
              " 'ne.': 212,\n",
              " '.ye': 83,\n",
              " 'yea': 15,\n",
              " 'ear': 212,\n",
              " 'ars': 32,\n",
              " 'oli': 22,\n",
              " 'lit': 99,\n",
              " 'itu': 10,\n",
              " 'tud': 15,\n",
              " 'ude': 17,\n",
              " '.al': 327,\n",
              " 'llo': 26,\n",
              " 'low': 58,\n",
              " 'owe': 95,\n",
              " 'wed': 19,\n",
              " 'cop': 6,\n",
              " 'opy': 2,\n",
              " 'py.': 8,\n",
              " 'man': 197,\n",
              " 'any': 111,\n",
              " 'ny.': 85,\n",
              " 'mes': 47,\n",
              " '.ov': 40,\n",
              " 'ove': 109,\n",
              " 'con': 150,\n",
              " 'ten': 86,\n",
              " 'hes': 92,\n",
              " 'ese': 56,\n",
              " 'opi': 6,\n",
              " 'pie': 12,\n",
              " 'wer': 159,\n",
              " 'meo': 16,\n",
              " 'eon': 19,\n",
              " 'eem': 17,\n",
              " 'em.': 200,\n",
              " 'com': 154,\n",
              " 'omf': 1,\n",
              " 'mfo': 1,\n",
              " 'ort': 88,\n",
              " 'rta': 42,\n",
              " 'tab': 14,\n",
              " 'abl': 65,\n",
              " 'ble': 148,\n",
              " '.ot': 60,\n",
              " 'oth': 124,\n",
              " '.qu': 77,\n",
              " 'que': 53,\n",
              " 'ues': 32,\n",
              " 'sti': 109,\n",
              " 'nyt': 26,\n",
              " 'yth': 47,\n",
              " 'ind': 125,\n",
              " 'rob': 34,\n",
              " 'obl': 29,\n",
              " 'lem': 72,\n",
              " 'not': 204,\n",
              " 'ot.': 207,\n",
              " 'how': 103,\n",
              " 'olv': 20,\n",
              " 'lve': 66,\n",
              " 'hel': 80,\n",
              " 'elp': 68,\n",
              " 'lp.': 60,\n",
              " 'nea': 32,\n",
              " 'arb': 4,\n",
              " 'rby': 1,\n",
              " 'dru': 8,\n",
              " 'rui': 11,\n",
              " 'uid': 10,\n",
              " 'ids': 7,\n",
              " '.ri': 93,\n",
              " 'rin': 97,\n",
              " 'anc': 74,\n",
              " 'nci': 65,\n",
              " 'cie': 12,\n",
              " 'ien': 47,\n",
              " '.st': 276,\n",
              " 'sta': 128,\n",
              " 'tat': 38,\n",
              " 'atu': 65,\n",
              " 'tue': 5,\n",
              " 'ue.': 46,\n",
              " 'odd': 12,\n",
              " 'dde': 24,\n",
              " 'des': 86,\n",
              " 'pla': 89,\n",
              " 'lac': 55,\n",
              " 'ace': 79,\n",
              " 'ce.': 312,\n",
              " 'sat': 15,\n",
              " 'tur': 148,\n",
              " 'ura': 23,\n",
              " 'rat': 54,\n",
              " 'pow': 43,\n",
              " 'aws': 7,\n",
              " 'ws.': 30,\n",
              " '.da': 116,\n",
              " 'dan': 48,\n",
              " 'ero': 17,\n",
              " 'ous': 104,\n",
              " 'us.': 99,\n",
              " '.en': 120,\n",
              " 'nti': 93,\n",
              " 'tit': 17,\n",
              " 'iti': 83,\n",
              " 'tie': 27,\n",
              " '.un': 123,\n",
              " 'unc': 24,\n",
              " 'nco': 16,\n",
              " 'omm': 32,\n",
              " 'wil': 116,\n",
              " 'ild': 41,\n",
              " '.hu': 99,\n",
              " 'hun': 50,\n",
              " 'unt': 78,\n",
              " 'beg': 5,\n",
              " 'ega': 14,\n",
              " 'gan': 21,\n",
              " 'hau': 9,\n",
              " 'aun': 8,\n",
              " 'cir': 8,\n",
              " 'irc': 8,\n",
              " 'rcl': 7,\n",
              " 'cle': 36,\n",
              " '.re': 327,\n",
              " 'ece': 29,\n",
              " 'cen': 42,\n",
              " 'ntl': 19,\n",
              " 'tly': 43,\n",
              " 'its': 112,\n",
              " 'ts.': 507,\n",
              " 'hop': 18,\n",
              " 'pin': 20,\n",
              " 'uls': 22,\n",
              " 'ls.': 83,\n",
              " 'arr': 46,\n",
              " 'rri': 43,\n",
              " 'rio': 42,\n",
              " 'ior': 23,\n",
              " 'ors': 54,\n",
              " 'lai': 26,\n",
              " 'aid': 44,\n",
              " 'id.': 128,\n",
              " '.ku': 5,\n",
              " 'kur': 5,\n",
              " 'urg': 8,\n",
              " 'rga': 16,\n",
              " 'ans': 68,\n",
              " 'hut': 9,\n",
              " '.de': 285,\n",
              " 'dea': 96,\n",
              " 'eal': 69,\n",
              " 'lik': 69,\n",
              " 'ike': 75,\n",
              " 'wan': 60,\n",
              " 'ant': 221,\n",
              " 'kil': 52,\n",
              " '.9.': 2,\n",
              " '.ph': 21,\n",
              " 'pha': 8,\n",
              " 'tom': 26,\n",
              " 'oms': 8,\n",
              " 'ms.': 50,\n",
              " 'hal': 48,\n",
              " '.nu': 10,\n",
              " 'num': 10,\n",
              " 'umb': 9,\n",
              " 'mbe': 30,\n",
              " 'ber': 55,\n",
              " 'per': 92,\n",
              " 'erh': 12,\n",
              " 'rha': 6,\n",
              " 'hap': 36,\n",
              " 'aps': 7,\n",
              " 'ps.': 35,\n",
              " '.ap': 43,\n",
              " 'app': 78,\n",
              " 'ppe': 71,\n",
              " 'ara': 39,\n",
              " 'ran': 63,\n",
              " 'nce': 223,\n",
              " 'dri': 14,\n",
              " 'riv': 13,\n",
              " 'ive': 240,\n",
              " 'off': 36,\n",
              " 'ff.': 34,\n",
              " 'rew': 36,\n",
              " 'ewa': 13,\n",
              " 'may': 43,\n",
              " 'ok.': 29,\n",
              " '.va': 30,\n",
              " 'vam': 17,\n",
              " 'amp': 58,\n",
              " 'mpi': 20,\n",
              " 'res': 282,\n",
              " '.ow': 19,\n",
              " 'own': 113,\n",
              " 'wne': 24,\n",
              " 'ner': 49,\n",
              " 'rsh': 10,\n",
              " 'shi': 23,\n",
              " 'hip': 9,\n",
              " 'ip.': 8,\n",
              " 'uts': 13,\n",
              " '.wr': 23,\n",
              " 'wre': 5,\n",
              " 'rea': 189,\n",
              " 'eat': 163,\n",
              " 'ath': 66,\n",
              " 'org': 36,\n",
              " 'rge': 18,\n",
              " 'etm': 3,\n",
              " 'tme': 6,\n",
              " 'men': 108,\n",
              " 'eno': 41,\n",
              " 'ots': 20,\n",
              " 'rem': 46,\n",
              " 'eme': 87,\n",
              " 'mem': 42,\n",
              " 'emb': 44,\n",
              " 'his': 217,\n",
              " 'erf': 37,\n",
              " 'rfu': 20,\n",
              " 'ful': 68,\n",
              " 'ul.': 62,\n",
              " '.op': 54,\n",
              " 'opp': 42,\n",
              " 'ppo': 57,\n",
              " 'pon': 63,\n",
              " 'nen': 44,\n",
              " 'no.': 102,\n",
              " 'tal': 96,\n",
              " 'al.': 178,\n",
              " '.ev': 98,\n",
              " 'ven': 99,\n",
              " 'ope': 37,\n",
              " 'pe.': 17,\n",
              " 'def': 21,\n",
              " 'efe': 21,\n",
              " 'fea': 28,\n",
              " '.hi': 249,\n",
              " 'him': 111,\n",
              " 'im.': 213,\n",
              " 'so.': 110,\n",
              " 'fig': 43,\n",
              " 'igh': 214,\n",
              " 'ndr': 71,\n",
              " 'rak': 4,\n",
              " '.ro': 48,\n",
              " 'roo': 21,\n",
              " 'oot': 8,\n",
              " 'ar.': 145,\n",
              " 'mag': 73,\n",
              " 'agi': 56,\n",
              " 'gic': 47,\n",
              " 'ic.': 63,\n",
              " 'rb.': 4,\n",
              " '.ke': 33,\n",
              " 'kee': 18,\n",
              " 'eep': 23,\n",
              " 'ep.': 16,\n",
              " '.ba': 125,\n",
              " 'bay': 1,\n",
              " 'mer': 47,\n",
              " 'rel': 44,\n",
              " 'ely': 75,\n",
              " 'ndl': 14,\n",
              " 'dle': 17,\n",
              " 'tan': 106,\n",
              " 'nds': 56,\n",
              " 'spr': 2,\n",
              " 'pri': 51,\n",
              " 'ink': 82,\n",
              " 'nkl': 1,\n",
              " 'kle': 1,\n",
              " '.up': 35,\n",
              " 'upo': 1,\n",
              " '.fl': 40,\n",
              " 'fla': 14,\n",
              " 'lam': 90,\n",
              " 'oun': 136,\n",
              " 'und': 177,\n",
              " 'lpf': 2,\n",
              " 'pfu': 2,\n",
              " '.il': 100,\n",
              " 'emi': 55,\n",
              " 'was': 105,\n",
              " '.sl': 28,\n",
              " 'sla': 13,\n",
              " 'lay': 18,\n",
              " 'hey': 250,\n",
              " 'ey.': 273,\n",
              " '.ni': 29,\n",
              " 'nig': 40,\n",
              " 'fie': 23,\n",
              " 'ier': 18,\n",
              " 'erc': 22,\n",
              " 'rce': 48,\n",
              " 'ces': 79,\n",
              " 'hem': 192,\n",
              " 'did': 65,\n",
              " '.jo': 13,\n",
              " 'job': 10,\n",
              " 'ob.': 13,\n",
              " 'gon': 26,\n",
              " 'spl': 7,\n",
              " 'len': 30,\n",
              " 'end': 114,\n",
              " 'ndi': 53,\n",
              " '.am': 62,\n",
              " 'am.': 36,\n",
              " 'gra': 75,\n",
              " 'tef': 6,\n",
              " 'efu': 24,\n",
              " 'whi': 63,\n",
              " 'hic': 47,\n",
              " 'ich': 42,\n",
              " 'ch.': 128,\n",
              " 'riz': 11,\n",
              " 'ize': 24,\n",
              " 'ze.': 25,\n",
              " '.ta': 133,\n",
              " 'tak': 62,\n",
              " 'als': 43,\n",
              " 'lso': 25,\n",
              " 'sac': 10,\n",
              " 'ack': 83,\n",
              " 'ck.': 161,\n",
              " 'hol': 33,\n",
              " 'oly': 8,\n",
              " 'sal': 78,\n",
              " 'car': 56,\n",
              " 'rry': 23,\n",
              " 'fen': 22,\n",
              " 'mig': 31,\n",
              " 'sef': 2,\n",
              " '.im': 189,\n",
              " 'ste': 213,\n",
              " 'key': 13,\n",
              " 'doo': 4,\n",
              " 'oor': 8,\n",
              " 'ref': 29,\n",
              " 'ull': 53,\n",
              " 'mom': 8,\n",
              " 'rig': 77,\n",
              " '.te': 91,\n",
              " '.ag': 75,\n",
              " 'aga': 29,\n",
              " 'gai': 54,\n",
              " 'ain': 178,\n",
              " 'rds': 38,\n",
              " 'nta': 26,\n",
              " 'tai': 32,\n",
              " 'alp': 8,\n",
              " 'lps': 9,\n",
              " 'bru': 8,\n",
              " 'rux': 7,\n",
              " 'uxa': 7,\n",
              " 'xae': 1,\n",
              " 'ae.': 1,\n",
              " 'fle': 18,\n",
              " 'edd': 8,\n",
              " 'der': 156,\n",
              " '.ga': 37,\n",
              " 'gar': 34,\n",
              " 'ark': 30,\n",
              " 'rki': 19,\n",
              " '.if': 92,\n",
              " 'if.': 93,\n",
              " '.ch': 119,\n",
              " 'cho': 27,\n",
              " 'hoo': 14,\n",
              " 'oos': 13,\n",
              " 'ose': 82,\n",
              " 'san': 16,\n",
              " 'nct': 17,\n",
              " 'ctu': 23,\n",
              " 'tua': 14,\n",
              " 'uar': 48,\n",
              " 'sto': 76,\n",
              " 'tor': 50,\n",
              " 'nee': 83,\n",
              " 'eed': 112,\n",
              " '.gh': 26,\n",
              " 'gho': 29,\n",
              " 'hos': 53,\n",
              " 'ret': 65,\n",
              " 'etu': 18,\n",
              " 'urn': 52,\n",
              " 'rn.': 70,\n",
              " 'alm': 11,\n",
              " 'lm.': 2,\n",
              " 'pec': 80,\n",
              " 'eci': 61,\n",
              " 'cif': 11,\n",
              " 'ifi': 24,\n",
              " 'fic': 31,\n",
              " 'ali': 90,\n",
              " 'lin': 123,\n",
              " 'na.': 46,\n",
              " '.sh': 212,\n",
              " 'she': 95,\n",
              " '.tu': 29,\n",
              " 'rne': 33,\n",
              " '.tr': 168,\n",
              " 'try': 50,\n",
              " 'ryi': 9,\n",
              " 'yin': 31,\n",
              " 'pos': 48,\n",
              " 'oss': 22,\n",
              " 'sse': 31,\n",
              " 'ses': 62,\n",
              " 'ssi': 57,\n",
              " 'sio': 43,\n",
              " '.ra': 76,\n",
              " 'ite': 45,\n",
              " 'tem': 101,\n",
              " 'neh': 14,\n",
              " 'eha': 13,\n",
              " 'ale': 53,\n",
              " 'enn': 10,\n",
              " 'nni': 26,\n",
              " 'nia': 9,\n",
              " 'ias': 4,\n",
              " 'mir': 31,\n",
              " 'irr': 29,\n",
              " 'rro': 47,\n",
              " 'ror': 29,\n",
              " 'oft': 14,\n",
              " 'fte': 45,\n",
              " 'ved': 73,\n",
              " 'rop': 25,\n",
              " 'oph': 14,\n",
              " 'phe': 23,\n",
              " 'het': 10,\n",
              " 'ets': 49,\n",
              " 'ora': 13,\n",
              " 'rac': 55,\n",
              " 'acl': 8,\n",
              " '.ac': 61,\n",
              " 'acc': 26,\n",
              " 'ccu': 14,\n",
              " 'cur': 42,\n",
              " 'tho': 90,\n",
              " 'hou': 142,\n",
              " 'gh.': 72,\n",
              " 'onf': 17,\n",
              " 'nfu': 12,\n",
              " 'fus': 7,\n",
              " 'usi': 54,\n",
              " 'sin': 90,\n",
              " 'ngl': 13,\n",
              " 'gly': 11,\n",
              " 'eto': 4,\n",
              " 'tol': 13,\n",
              " 'old': 56,\n",
              " '.fu': 53,\n",
              " 'fut': 14,\n",
              " 'utu': 11,\n",
              " 'ure': 228,\n",
              " '.ad': 38,\n",
              " 'adv': 15,\n",
              " 'dvi': 8,\n",
              " 'vic': 38,\n",
              " 'ice': 76,\n",
              " 'ski': 18,\n",
              " 'usu': 15,\n",
              " 'sua': 16,\n",
              " 'ual': 32,\n",
              " 'quo': 33,\n",
              " 'uot': 32,\n",
              " 'otw': 4,\n",
              " 'twh': 4,\n",
              " '.fa': 109,\n",
              " 'fai': 16,\n",
              " 'air': 22,\n",
              " 'llq': 3,\n",
              " 'lqu': 4,\n",
              " 'dis': 60,\n",
              " 'ist': 86,\n",
              " 'ngu': 9,\n",
              " 'gui': 11,\n",
              " 'uis': 7,\n",
              " 'ish': 43,\n",
              " 'hed': 24,\n",
              " 'urt': 15,\n",
              " 'rte': 17,\n",
              " 'teo': 2,\n",
              " 'eou': 5,\n",
              " '.sm': 14,\n",
              " 'sma': 14,\n",
              " 'mas': 29,\n",
              " 'ash': 15,\n",
              " 'cis': 13,\n",
              " 'ise': 48,\n",
              " 'nas': 31,\n",
              " '.pa': 108,\n",
              " 'art': 60,\n",
              " 'rts': 18,\n",
              " 'sem': 10,\n",
              " 'mbl': 8,\n",
              " 'gav': 5,\n",
              " '.ef': 26,\n",
              " 'eff': 26,\n",
              " 'ffe': 57,\n",
              " 'fec': 35,\n",
              " '.ce': 46,\n",
              " 'cea': 8,\n",
              " 'sed': 71,\n",
              " 'att': 102,\n",
              " 'tta': 45,\n",
              " 'tac': 101,\n",
              " 'cki': 30,\n",
              " 'ems': 24,\n",
              " 'nde': 144,\n",
              " 'rst': 58,\n",
              " 'too': 38,\n",
              " 'til': 32,\n",
              " 'doe': 18,\n",
              " 'oes': 22,\n",
              " 'bel': 43,\n",
              " 'eli': 107,\n",
              " 'lie': 47,\n",
              " 'iev': 31,\n",
              " 'wn.': 76,\n",
              " 'nts': 117,\n",
              " 'ddi': 15,\n",
              " 'din': 77,\n",
              " 'mus': 40,\n",
              " 'ust': 103,\n",
              " '.lo': 134,\n",
              " 'loc': 11,\n",
              " 'oca': 5,\n",
              " 'cal': 83,\n",
              " 'soo': 21,\n",
              " 'ths': 8,\n",
              " 'hsa': 2,\n",
              " 'aye': 6,\n",
              " 'yer': 4,\n",
              " 'nks': 25,\n",
              " 'far': 20,\n",
              " 'ewe': 19,\n",
              " 'yes': 48,\n",
              " 'ben': 5,\n",
              " 'ene': 69,\n",
              " 'saw': 9,\n",
              " 'bef': 19,\n",
              " 'efo': 22,\n",
              " 'ita': 30,\n",
              " 'tag': 11,\n",
              " 'omb': 40,\n",
              " 'mbs': 5,\n",
              " 'kni': 12,\n",
              " 'hts': 15,\n",
              " 'ied': 30,\n",
              " 'ges': 27,\n",
              " 'ava': 2,\n",
              " 'van': 12,\n",
              " 'ded': 60,\n",
              " 'hon': 4,\n",
              " 'ono': 4,\n",
              " 'nor': 22,\n",
              " 'nst': 83,\n",
              " '.bl': 86,\n",
              " 'bla': 11,\n",
              " '.sk': 24,\n",
              " 'sku': 7,\n",
              " 'kul': 9,\n",
              " '.el': 64,\n",
              " 'lle': 83,\n",
              " 'lev': 17,\n",
              " 'rer': 12,\n",
              " 'eri': 89,\n",
              " 'ris': 42,\n",
              " 'lta': 6,\n",
              " 'tar': 30,\n",
              " 'hti': 11,\n",
              " 'bea': 44,\n",
              " 'ast': 119,\n",
              " 'rss': 1,\n",
              " 'mb.': 21,\n",
              " '.sy': 9,\n",
              " 'sym': 8,\n",
              " 'ymb': 9,\n",
              " 'mbo': 13,\n",
              " 'bol': 15,\n",
              " 'lic': 52,\n",
              " 'los': 34,\n",
              " 'mis': 51,\n",
              " 'iss': 38,\n",
              " 'las': 18,\n",
              " 'rey': 3,\n",
              " 'eyn': 1,\n",
              " 'yna': 1,\n",
              " 'nar': 10,\n",
              " 'ord': 70,\n",
              " 'rdi': 13,\n",
              " 'inn': 20,\n",
              " 'nnk': 1,\n",
              " 'nke': 5,\n",
              " 'epe': 3,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CREATING A MODEL"
      ],
      "metadata": {
        "id": "iUYL2kf6h-x1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A smaller angle between the language vector and the vector made from the given text implies greater similarity. To get the angle we compute cosine of the angle between the vectors. Since greater cosine means smaller angle, we directly use the cosine as the score for a given language. Language with the maximum score is the predicted language."
      ],
      "metadata": {
        "id": "Ru5dmctIU_ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cosine_model:\n",
        "  def __init__(self):\n",
        "    # initializing language to trigram counts\n",
        "    self.lang_trigram = {}\n",
        "\n",
        "  # train model (create trigram vector for given language)\n",
        "  def train(self, language, preprocessed_data):\n",
        "    self.lang_trigram[language] = create_trigram_vector(preprocessed_data)\n",
        "\n",
        "  # function to return vector length given trigram counts\n",
        "  def vec_length(self, trigram_count):\n",
        "    sum = 0\n",
        "    for key, value in trigram_count.items():\n",
        "      sum += value*value\n",
        "    length = math.sqrt(sum)\n",
        "    return length\n",
        "\n",
        "  # function return cosine of language vector and text trigram vector\n",
        "  def cosine(self, language, text_trigram_vec):\n",
        "    dot = 0.0\n",
        "    # for given language look up the trigram vector\n",
        "    lang_count = self.lang_trigram[language]\n",
        "    # calculating dot product\n",
        "    for key, value in text_trigram_vec.items():\n",
        "      if key in lang_count:\n",
        "        dot += (value * lang_count[key])\n",
        "    # calculating cosine using dot product of the vectors and their lengths\n",
        "    cosine = dot / (self.vec_length(lang_count) * self.vec_length(text_trigram_vec))\n",
        "    return cosine\n",
        "\n",
        "  # predicting language for text given\n",
        "  def predict(self, text):\n",
        "    trigram_text = create_trigram_vector(text)\n",
        "    result = {}\n",
        "    for key, value in self.lang_trigram.items():\n",
        "      result[key] = self.cosine(key, trigram_text)\n",
        "        \n",
        "    result = sorted(result.items(), key = lambda x: -x[1])\n",
        "    if result[0][1] == 0.0:\n",
        "      print('\\ncannot detect language')\n",
        "    else:\n",
        "      print('\\nlanguage of given text document is most likely to be: ', result[0][0])\n",
        "    return result[0][0]\n"
      ],
      "metadata": {
        "id": "otw5OJ-5cKbn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING OUT THE MODEL"
      ],
      "metadata": {
        "id": "qfIsDLD70AB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "training the model"
      ],
      "metadata": {
        "id": "s4-xhi3Y0Eix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = cosine_model()\n",
        "m.train('English', preprocess_data(load_training_data('English')))\n",
        "m.train('French', preprocess_data(load_training_data('French')))\n",
        "m.train('Czech', preprocess_data(load_training_data('Czech')))\n",
        "m.train('German', preprocess_data(load_training_data('German')))\n",
        "m.train('Hungarian', preprocess_data(load_training_data('Hungarian')))\n",
        "m.train('Italian', preprocess_data(load_training_data('Italian')))\n",
        "m.train('Polish', preprocess_data(load_training_data('Polish')))\n",
        "m.train('Russian', preprocess_data(load_training_data('Russian')))\n",
        "m.train('Spanish', preprocess_data(load_training_data('Spanish')))"
      ],
      "metadata": {
        "id": "sptxLu48jLpE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with an english paragraph"
      ],
      "metadata": {
        "id": "R9vuT0F00WAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'English'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzmhQtfOsu5m",
        "outputId": "5e42c893-2d8a-4994-d2c1-46c8a0077a8b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Along with the smooth flow of sentences, a paragraph’s coherence may also be related to its length. If you have written a very long paragraph, one that fills a double-spaced typed page, for example, you should check it carefully to see if it should start a new paragraph where the original paragraph wanders from its controlling idea. On the other hand, if a paragraph is very short (only one or two sentences, perhaps), you may need to develop its controlling idea more thoroughly, or combine it with another paragraph.\n",
            "\n",
            "language of given text document is most likely to be:  English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a french paragraph"
      ],
      "metadata": {
        "id": "dxv20ifZ1AVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'French'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad83bc7-b259-4098-ab49-4f8606078c2b",
        "id": "qBsK5RZ-1AVI"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Je m’appelle Jessica. Je suis une fille, je suis française et j’ai treize ans. Je vais à l’école à Nice, mais j’habite à Cagnes-Sur-Mer. J’ai deux frères. Le premier s’appelle Thomas, il a quatorze ans. Le second s’appelle Yann et il a neuf ans. Mon papa est italien et il est fleuriste. Ma mère est allemande et est avocate. Mes frères et moi parlons français, italien et allemand à la maison. Nous avons une grande maison avec un chien, un poisson et deux chats.\n",
            "\n",
            "language of given text document is most likely to be:  French\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a czech paragraph"
      ],
      "metadata": {
        "id": "2i41gP091XMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Czech'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe2538b-e18a-4b1f-fa29-fa8fd178283f",
        "id": "ZoNuUeSu1XMO"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Pan Novák stojí na nádraží a vyhlíží svůj vlak. „Už tu měl dávno být, asi má zpoždění,“ říká si. Dnes jede na pracovní schůzku do Brna. V Brně se mu líbí. Je to krásné město a stále se tam něco děje: výstavy, festivaly, koncerty, mají tam dobré restaurace a hezkou přírodu. Škoda jen, že se tam v centru špatně parkuje.\n",
            "\n",
            "language of given text document is most likely to be:  Czech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a german paragraph"
      ],
      "metadata": {
        "id": "mxP54AUb1mSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'German'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115c4535-e859-42e0-801e-8e6527e2d623",
        "id": "YmvKjRQu1mS0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Familie Müller plant ihren Urlaub. Sie geht in ein Reisebüro und lässt sich von einem Angestellten beraten. Als Reiseziel wählt sie Mallorca aus. Familie Müller bucht einen Flug auf die Mittelmeerinsel. Sie bucht außerdem zwei Zimmer in einem großen Hotel direkt am Strand. Familie Müller badet gerne im Meer.\n",
            "\n",
            "language of given text document is most likely to be:  German\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with an hungarian paragraph"
      ],
      "metadata": {
        "id": "fx398_pJ1x23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Hungarian'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c76a7c8-fa51-4240-cef6-02e3eb8a3859",
        "id": "nU7ap00M1x24"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: A nevelésnek az emberi személyiség teljes kibontakoztatására, valamint az emberi jogok és alapvető szabadságok tiszteletbentartásának megerősítésére kell irányulnia. A nevelésnek elő kell segítenie a nemzetek, valamint az összes faji és vallási csoportok közötti megértést, türelmet és barátságot, valamint az Egyesült Nemzetek által a béke fenntartásának érdekében kifejtett tevékenység kifejlődését. 3) A szülőket elsőbbségi jog illeti meg a gyermekeiknek adandó nevelés megválasztásában.\n",
            "\n",
            "language of given text document is most likely to be:  Hungarian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with an italian paragraph"
      ],
      "metadata": {
        "id": "8zkuLxJT2EZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Italian'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09aab242-3073-4db5-b79a-e588b74df0a3",
        "id": "XQ1KhjOt2EZc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: La nostra famiglia è composta anche da altre due persone, i nostri figli, Manuela che ha diciassette anni, e Marco che ha quindici anni, e poi c'è anche Tremendo, il cane che vive con noi da nove anni, ed è parte della famiglia. Viviamo tutti nella nostra splendida casa con un grande giardino.\n",
            "\n",
            "language of given text document is most likely to be:  Italian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a polish paragraph"
      ],
      "metadata": {
        "id": "n3-X3Bee2ULU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Polish'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803b1f27-01a9-4261-ac99-87d484f8da18",
        "id": "0GNmvF622ULV"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Każdego roku Mateusz nie może się doczekać tego dnia. Już wiele tygodni przed tą datą starannie planuje całe przyjęcie. Zaczyna od wyboru listy gości. Nie można oczywiście zapomnieć o rodzinie. Dlatego zawsze mile widziani są: mama, tata, brat oraz siostra. Czasem udaje się też zaprosić babcię, jeżeli dobrze się czuje. Przecież im więcej gości tym lepiej - nie tylko ze względu na prezenty. Oprócz gości będących osobami z jego rodziny, Mateusz nigdy nie zapomina też o swoich kolegach i przyjaciołach. Co to byłyby za urodziny, na których nie pojawiłby się Kacper, Ola, Wojtek albo Dawid?\n",
            "\n",
            "language of given text document is most likely to be:  Polish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a russian paragraph"
      ],
      "metadata": {
        "id": "-SWgfKgR2m9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Russian'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315c6f80-d954-4f06-b415-515b2216a9ec",
        "id": "iur5CQyT2m9j"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Я с детства хотел завести собаку, но родители мне не разрешали. Пока я был ребёнком, у меня жил хомяк Хома. Хома был очень маленький и пушистый. Его шерсть была средней длинны и коричневого цвета. Родители купили большую клетку для него, с двумя этажами. Я был очень рад, когда у меня появился маленький друг. Было очень весело смотреть как Хома бегает в колесе. Мне нравилось кормить его морковкой и орехами\n",
            "\n",
            "language of given text document is most likely to be:  Russian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a spanish paragraph"
      ],
      "metadata": {
        "id": "F7S_7yXU21dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Spanish'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab049b1-050b-4b12-b97f-4433d64dfd0b",
        "id": "x_shx40F21dS"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Hoy hace mucho frío. Es invierno y todas las calles están cubiertas de nieve. Dentro de poco vendrá la primavera y con ella el sol y el tiempo cálido. La semana pasada estuvo de lluvia y tormenta. Incluso un rayo cayó encima de la campana de la catedral, pero no ocurrió nada. Los truenos siempre me han dado miedo y mucho respeto. Pero tenemos suerte... pues la previsión del tiempo para mañana es muy buena. Dicen que hoy habrá heladas y por la tarde granizo, pero mañana el día será soleado. A ver si tengo suerte y veo algún arcoíris.\n",
            "\n",
            "language of given text document is most likely to be:  Spanish\n"
          ]
        }
      ]
    }
  ]
}