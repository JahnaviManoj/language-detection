{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zt0uT-7V9iH_"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip language-training.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPMXsncZGZ_V",
        "outputId": "45a99726-6112-4e2a-f5ca-4345a0e15667"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  language-training.zip\n",
            "   creating: language-training/Czech/\n",
            "  inflating: language-training/Czech/23_cm_her101  \n",
            "  inflating: language-training/Czech/bestiary  \n",
            "  inflating: language-training/Czech/character  \n",
            "  inflating: language-training/Czech/cn_jaskier07  \n",
            "  inflating: language-training/Czech/cn_julian01  \n",
            "  inflating: language-training/Czech/cn_kalkstein10  \n",
            "  inflating: language-training/Czech/cn_lady01  \n",
            "  inflating: language-training/Czech/cn_leuvaarden10  \n",
            "  inflating: language-training/Czech/cn_raymond05  \n",
            "  inflating: language-training/Czech/cn_shani19  \n",
            "  inflating: language-training/Czech/cn_talar01  \n",
            "  inflating: language-training/Czech/cn_triss01  \n",
            "  inflating: language-training/Czech/cn_vincent02  \n",
            "  inflating: language-training/Czech/tutorial  \n",
            "   creating: language-training/English/\n",
            "  inflating: language-training/English/23_cm_her101  \n",
            "  inflating: language-training/English/bestiary  \n",
            "  inflating: language-training/English/character  \n",
            "  inflating: language-training/English/cn_jaskier07  \n",
            "  inflating: language-training/English/cn_julian01  \n",
            "  inflating: language-training/English/cn_kalkstein10  \n",
            "  inflating: language-training/English/cn_lady01  \n",
            "  inflating: language-training/English/cn_leuvaarden10  \n",
            "  inflating: language-training/English/cn_raymond05  \n",
            "  inflating: language-training/English/cn_shani19  \n",
            "  inflating: language-training/English/cn_talar01  \n",
            "  inflating: language-training/English/cn_triss01  \n",
            "  inflating: language-training/English/cn_vincent02  \n",
            "  inflating: language-training/English/tutorial  \n",
            "   creating: language-training/French/\n",
            "  inflating: language-training/French/23_cm_her101  \n",
            "  inflating: language-training/French/bestiary  \n",
            "  inflating: language-training/French/character  \n",
            "  inflating: language-training/French/cn_jaskier07  \n",
            "  inflating: language-training/French/cn_julian01  \n",
            "  inflating: language-training/French/cn_kalkstein10  \n",
            "  inflating: language-training/French/cn_lady01  \n",
            "  inflating: language-training/French/cn_leuvaarden10  \n",
            "  inflating: language-training/French/cn_raymond05  \n",
            "  inflating: language-training/French/cn_shani19  \n",
            "  inflating: language-training/French/cn_talar01  \n",
            "  inflating: language-training/French/cn_triss01  \n",
            "  inflating: language-training/French/cn_vincent02  \n",
            "  inflating: language-training/French/tutorial  \n",
            "   creating: language-training/German/\n",
            "  inflating: language-training/German/23_cm_her101  \n",
            "  inflating: language-training/German/bestiary  \n",
            "  inflating: language-training/German/character  \n",
            "  inflating: language-training/German/cn_jaskier07  \n",
            "  inflating: language-training/German/cn_julian01  \n",
            "  inflating: language-training/German/cn_kalkstein10  \n",
            "  inflating: language-training/German/cn_lady01  \n",
            "  inflating: language-training/German/cn_leuvaarden10  \n",
            "  inflating: language-training/German/cn_raymond05  \n",
            "  inflating: language-training/German/cn_shani19  \n",
            "  inflating: language-training/German/cn_talar01  \n",
            "  inflating: language-training/German/cn_triss01  \n",
            "  inflating: language-training/German/cn_vincent02  \n",
            "  inflating: language-training/German/tutorial  \n",
            "   creating: language-training/Hungarian/\n",
            "  inflating: language-training/Hungarian/23_cm_her101  \n",
            "  inflating: language-training/Hungarian/bestiary  \n",
            "  inflating: language-training/Hungarian/character  \n",
            "  inflating: language-training/Hungarian/cn_jaskier07  \n",
            "  inflating: language-training/Hungarian/cn_julian01  \n",
            "  inflating: language-training/Hungarian/cn_kalkstein10  \n",
            "  inflating: language-training/Hungarian/cn_lady01  \n",
            "  inflating: language-training/Hungarian/cn_leuvaarden10  \n",
            "  inflating: language-training/Hungarian/cn_raymond05  \n",
            "  inflating: language-training/Hungarian/cn_shani19  \n",
            "  inflating: language-training/Hungarian/cn_talar01  \n",
            "  inflating: language-training/Hungarian/cn_triss01  \n",
            "  inflating: language-training/Hungarian/cn_vincent02  \n",
            "  inflating: language-training/Hungarian/tutorial  \n",
            "   creating: language-training/Italian/\n",
            "  inflating: language-training/Italian/23_cm_her101  \n",
            "  inflating: language-training/Italian/bestiary  \n",
            "  inflating: language-training/Italian/character  \n",
            "  inflating: language-training/Italian/cn_jaskier07  \n",
            "  inflating: language-training/Italian/cn_julian01  \n",
            "  inflating: language-training/Italian/cn_kalkstein10  \n",
            "  inflating: language-training/Italian/cn_lady01  \n",
            "  inflating: language-training/Italian/cn_leuvaarden10  \n",
            "  inflating: language-training/Italian/cn_raymond05  \n",
            "  inflating: language-training/Italian/cn_shani19  \n",
            "  inflating: language-training/Italian/cn_talar01  \n",
            "  inflating: language-training/Italian/cn_triss01  \n",
            "  inflating: language-training/Italian/cn_vincent02  \n",
            "  inflating: language-training/Italian/tutorial  \n",
            "   creating: language-training/Polish/\n",
            "  inflating: language-training/Polish/23_cm_her101  \n",
            "  inflating: language-training/Polish/bestiary  \n",
            "  inflating: language-training/Polish/character  \n",
            "  inflating: language-training/Polish/cn_jaskier07  \n",
            "  inflating: language-training/Polish/cn_julian01  \n",
            "  inflating: language-training/Polish/cn_kalkstein10  \n",
            "  inflating: language-training/Polish/cn_lady01  \n",
            "  inflating: language-training/Polish/cn_leuvaarden10  \n",
            "  inflating: language-training/Polish/cn_raymond05  \n",
            "  inflating: language-training/Polish/cn_shani19  \n",
            "  inflating: language-training/Polish/cn_talar01  \n",
            "  inflating: language-training/Polish/cn_triss01  \n",
            "  inflating: language-training/Polish/cn_vincent02  \n",
            "  inflating: language-training/Polish/tutorial  \n",
            "   creating: language-training/Russian/\n",
            "  inflating: language-training/Russian/23_cm_her101  \n",
            "  inflating: language-training/Russian/bestiary  \n",
            "  inflating: language-training/Russian/character  \n",
            "  inflating: language-training/Russian/cn_jaskier07  \n",
            "  inflating: language-training/Russian/cn_julian01  \n",
            "  inflating: language-training/Russian/cn_kalkstein10  \n",
            "  inflating: language-training/Russian/cn_lady01  \n",
            "  inflating: language-training/Russian/cn_leuvaarden10  \n",
            "  inflating: language-training/Russian/cn_raymond05  \n",
            "  inflating: language-training/Russian/cn_shani19  \n",
            "  inflating: language-training/Russian/cn_talar01  \n",
            "  inflating: language-training/Russian/cn_triss01  \n",
            "  inflating: language-training/Russian/cn_vincent02  \n",
            "  inflating: language-training/Russian/tutorial  \n",
            "   creating: language-training/Spanish/\n",
            "  inflating: language-training/Spanish/23_cm_her101  \n",
            "  inflating: language-training/Spanish/bestiary  \n",
            "  inflating: language-training/Spanish/character  \n",
            "  inflating: language-training/Spanish/cn_jaskier07  \n",
            "  inflating: language-training/Spanish/cn_julian01  \n",
            "  inflating: language-training/Spanish/cn_kalkstein10  \n",
            "  inflating: language-training/Spanish/cn_lady01  \n",
            "  inflating: language-training/Spanish/cn_leuvaarden10  \n",
            "  inflating: language-training/Spanish/cn_raymond05  \n",
            "  inflating: language-training/Spanish/cn_shani19  \n",
            "  inflating: language-training/Spanish/cn_talar01  \n",
            "  inflating: language-training/Spanish/cn_triss01  \n",
            "  inflating: language-training/Spanish/cn_vincent02  \n",
            "  inflating: language-training/Spanish/tutorial  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOADING TRAINING DATA"
      ],
      "metadata": {
        "id": "js-luyt2XeE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading training data from folder for given language"
      ],
      "metadata": {
        "id": "kNJ31nZoHQ9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_training_data(lang):\n",
        "  files = ['23_cm_her101', 'bestiary', 'character', 'cn_jaskier07', 'cn_julian01', 'cn_kalkstein10', 'cn_lady01', 'cn_leuvaarden10', 'cn_raymond05', 'cn_shani19', 'cn_talar01', 'cn_triss01', 'cn_vincent02', 'tutorial']\n",
        "\n",
        "  text = []\n",
        "  for f in files:\n",
        "    para = open('language-training/' + lang + '/' + f, 'r', encoding=\"utf8\").readlines()\n",
        "    for line in para:\n",
        "      text.append(line)\n",
        "  return text"
      ],
      "metadata": {
        "id": "uYkJpY0EHa40"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data is an array of paragraphs. for example here is eng_text[3]"
      ],
      "metadata": {
        "id": "rbpxMedJH2GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_text = load_training_data('English')\n",
        "eng_text[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "arSadJc6H7WU",
        "outputId": "47b41932-0bf7-4e7d-c440-7cb47304fd01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I see you are a witcher. Has a villager finally sought to do something about the midday ladies?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPROCESSING TRAINING DATA"
      ],
      "metadata": {
        "id": "LY5zRRLfXiRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(text):\n",
        "  ret_words = []\n",
        "  for sentence in text:\n",
        "    words = sentence.split()\n",
        "    for word in words:\n",
        "      cleaned_word = re.sub(r'[\\W]', '', word)\n",
        "      if cleaned_word != '':\n",
        "        ret_words.append(cleaned_word.lower())\n",
        "  return ret_words"
      ],
      "metadata": {
        "id": "G89BQmhZXl-d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the english text. For example here is pre-process for [\"'I see you are a witcher. Has a villager finally sought to do something about the midday ladies?\\n'\"]. notice stripping of special characters such as ?"
      ],
      "metadata": {
        "id": "hRBN5iUoZ61f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_words = preprocess_data([\"'I see you are a witcher. Has a villager finally sought to do something about the midday ladies?\\n'\"])\n",
        "eng_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DbNs9fwY8tY",
        "outputId": "ee5ad3e8-3762-43fa-c4af-1cf68d3da180"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'see',\n",
              " 'you',\n",
              " 'are',\n",
              " 'a',\n",
              " 'witcher',\n",
              " 'has',\n",
              " 'a',\n",
              " 'villager',\n",
              " 'finally',\n",
              " 'sought',\n",
              " 'to',\n",
              " 'do',\n",
              " 'something',\n",
              " 'about',\n",
              " 'the',\n",
              " 'midday',\n",
              " 'ladies']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COUNTING NUMBER OF TIMES A TRIGRAM WAS OBSERVED"
      ],
      "metadata": {
        "id": "z7E05Cpoa83P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through this function, we get counts of each trigram. Now for a given text in a language, we can create an n-dimensional vector where each trigram corresponds to a dimnension and the number of times a trigram was observed is the value for that dimension."
      ],
      "metadata": {
        "id": "uIKpc5EVTIOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_trigram_vector(words):\n",
        "  trigram_vector = {}\n",
        "  for w in words:\n",
        "    ch = '.' + w + '.'\n",
        "    for c1, c2, c3 in zip(ch, ch[1:], ch[2:]):\n",
        "      trigram_vector[c1+c2+c3] = trigram_vector.get(c1+c2+c3, 0) + 1\n",
        "  return trigram_vector"
      ],
      "metadata": {
        "id": "0CCbU3goa_-v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, creating trigram counts for the english language from the english words"
      ],
      "metadata": {
        "id": "eO5k-A_IcC-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_count = create_trigram_vector(eng_words)\n",
        "eng_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKbaA7urbXXY",
        "outputId": "f4986afc-b1ce-440d-b321-002cc3f81468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.i.': 690,\n",
              " '.do': 339,\n",
              " 'don': 131,\n",
              " 'ont': 177,\n",
              " 'nt.': 508,\n",
              " '.ha': 436,\n",
              " 'hav': 218,\n",
              " 'ave': 328,\n",
              " 've.': 535,\n",
              " '.ti': 81,\n",
              " 'tim': 108,\n",
              " 'ime': 111,\n",
              " 'me.': 409,\n",
              " '.no': 364,\n",
              " 'now': 258,\n",
              " 'ow.': 336,\n",
              " '.wh': 445,\n",
              " 'who': 88,\n",
              " 'ho.': 70,\n",
              " '.is': 323,\n",
              " 'is.': 534,\n",
              " '.it': 388,\n",
              " 'it.': 347,\n",
              " '.th': 2579,\n",
              " 'tha': 381,\n",
              " 'hat': 493,\n",
              " 'at.': 583,\n",
              " 'the': 1990,\n",
              " 'he.': 1441,\n",
              " '.go': 150,\n",
              " 'god': 26,\n",
              " 'ods': 17,\n",
              " 'ds.': 161,\n",
              " '.le': 185,\n",
              " 'led': 107,\n",
              " 'ed.': 865,\n",
              " '.to': 1046,\n",
              " 'to.': 959,\n",
              " '.me': 307,\n",
              " '.gr': 136,\n",
              " 'gre': 56,\n",
              " 'ree': 53,\n",
              " 'eet': 18,\n",
              " 'eti': 26,\n",
              " 'tin': 131,\n",
              " 'ing': 886,\n",
              " 'ngs': 52,\n",
              " 'gs.': 57,\n",
              " '.my': 180,\n",
              " 'my.': 217,\n",
              " '.na': 39,\n",
              " 'nam': 18,\n",
              " 'ame': 50,\n",
              " '.ge': 191,\n",
              " 'ger': 138,\n",
              " 'era': 121,\n",
              " 'ral': 105,\n",
              " 'alt': 111,\n",
              " 'lt.': 117,\n",
              " '.se': 312,\n",
              " 'see': 105,\n",
              " 'ee.': 95,\n",
              " '.yo': 1072,\n",
              " 'you': 1086,\n",
              " 'ou.': 745,\n",
              " '.ar': 327,\n",
              " 'are': 364,\n",
              " 're.': 822,\n",
              " '.a.': 585,\n",
              " '.wi': 451,\n",
              " 'wit': 308,\n",
              " 'itc': 116,\n",
              " 'tch': 131,\n",
              " 'che': 209,\n",
              " 'her': 468,\n",
              " 'er.': 762,\n",
              " 'has': 67,\n",
              " 'as.': 304,\n",
              " '.vi': 112,\n",
              " 'vil': 18,\n",
              " 'ill': 278,\n",
              " 'lla': 22,\n",
              " 'lag': 15,\n",
              " 'age': 81,\n",
              " '.fi': 224,\n",
              " 'fin': 104,\n",
              " 'ina': 94,\n",
              " 'nal': 48,\n",
              " 'all': 274,\n",
              " 'lly': 84,\n",
              " 'ly.': 369,\n",
              " '.so': 351,\n",
              " 'sou': 43,\n",
              " 'oug': 96,\n",
              " 'ugh': 104,\n",
              " 'ght': 234,\n",
              " 'ht.': 165,\n",
              " 'do.': 139,\n",
              " 'som': 169,\n",
              " 'ome': 249,\n",
              " 'met': 89,\n",
              " 'eth': 74,\n",
              " 'thi': 383,\n",
              " 'hin': 262,\n",
              " 'ng.': 893,\n",
              " '.ab': 201,\n",
              " 'abo': 141,\n",
              " 'bou': 130,\n",
              " 'out': 231,\n",
              " 'ut.': 387,\n",
              " '.mi': 133,\n",
              " 'mid': 17,\n",
              " 'idd': 23,\n",
              " 'dda': 21,\n",
              " 'day': 25,\n",
              " 'ay.': 156,\n",
              " '.la': 129,\n",
              " 'lad': 72,\n",
              " 'adi': 12,\n",
              " 'die': 36,\n",
              " 'ies': 110,\n",
              " 'es.': 669,\n",
              " '.mo': 245,\n",
              " 'mor': 139,\n",
              " 'ore': 154,\n",
              " '.or': 131,\n",
              " 'or.': 378,\n",
              " 'les': 79,\n",
              " 'ess': 161,\n",
              " 'ss.': 153,\n",
              " 'lea': 93,\n",
              " 'ead': 101,\n",
              " 'ad.': 131,\n",
              " '.li': 185,\n",
              " 'lif': 32,\n",
              " 'ife': 30,\n",
              " 'fe.': 32,\n",
              " '.of': 589,\n",
              " 'of.': 552,\n",
              " '.he': 403,\n",
              " 'erm': 16,\n",
              " 'rmi': 14,\n",
              " 'mit': 19,\n",
              " 'ere': 339,\n",
              " 'ith': 213,\n",
              " 'th.': 267,\n",
              " '.fe': 83,\n",
              " 'few': 18,\n",
              " 'ew.': 55,\n",
              " '.lu': 17,\n",
              " 'lux': 3,\n",
              " 'uxu': 3,\n",
              " 'xur': 3,\n",
              " 'uri': 32,\n",
              " 'rie': 70,\n",
              " '.bu': 223,\n",
              " 'but': 160,\n",
              " '.ma': 277,\n",
              " 'mak': 37,\n",
              " 'ake': 118,\n",
              " 'ke.': 172,\n",
              " 'our': 357,\n",
              " 'urs': 67,\n",
              " 'rse': 47,\n",
              " 'sel': 54,\n",
              " 'elf': 36,\n",
              " 'lf.': 40,\n",
              " '.at': 160,\n",
              " '.ho': 166,\n",
              " 'hom': 6,\n",
              " 'han': 142,\n",
              " 'ank': 34,\n",
              " 'nk.': 81,\n",
              " '.by': 99,\n",
              " 'by.': 98,\n",
              " '.wa': 282,\n",
              " 'way': 73,\n",
              " '.sp': 115,\n",
              " 'spe': 109,\n",
              " 'pea': 86,\n",
              " 'eak': 39,\n",
              " 'ak.': 30,\n",
              " '.as': 150,\n",
              " 'ass': 59,\n",
              " 'ssu': 19,\n",
              " 'sum': 26,\n",
              " 'ume': 15,\n",
              " '.we': 259,\n",
              " 'wel': 87,\n",
              " 'ell': 185,\n",
              " 'll.': 512,\n",
              " '.ed': 6,\n",
              " 'edu': 6,\n",
              " 'duc': 11,\n",
              " 'uca': 2,\n",
              " 'cat': 27,\n",
              " 'ate': 198,\n",
              " 'ted': 159,\n",
              " '.co': 388,\n",
              " 'cor': 26,\n",
              " 'orr': 28,\n",
              " 'rre': 27,\n",
              " 'rec': 53,\n",
              " 'ect': 169,\n",
              " 'ct.': 70,\n",
              " 'pen': 48,\n",
              " 'ent': 341,\n",
              " 'mos': 37,\n",
              " 'ost': 77,\n",
              " 'st.': 322,\n",
              " 'ser': 49,\n",
              " 'erv': 42,\n",
              " 'rvi': 9,\n",
              " 'vin': 74,\n",
              " '.ki': 103,\n",
              " 'kin': 133,\n",
              " '.fo': 355,\n",
              " 'fol': 14,\n",
              " 'olt': 5,\n",
              " 'lte': 5,\n",
              " 'tes': 48,\n",
              " 'est': 201,\n",
              " '.di': 200,\n",
              " 'dip': 1,\n",
              " 'ipl': 4,\n",
              " 'plo': 12,\n",
              " 'lom': 1,\n",
              " 'oma': 21,\n",
              " 'mat': 59,\n",
              " '.wo': 197,\n",
              " 'wou': 48,\n",
              " 'oul': 177,\n",
              " 'uld': 112,\n",
              " 'ld.': 202,\n",
              " '.be': 454,\n",
              " 'be.': 228,\n",
              " 'for': 366,\n",
              " 'orw': 3,\n",
              " 'rwa': 15,\n",
              " 'war': 62,\n",
              " 'ard': 133,\n",
              " 'rd.': 112,\n",
              " 'ask': 25,\n",
              " 'sk.': 26,\n",
              " 'wha': 155,\n",
              " '.in': 644,\n",
              " 'ins': 96,\n",
              " 'nsp': 11,\n",
              " 'spi': 35,\n",
              " 'pir': 29,\n",
              " 'ire': 91,\n",
              " 'red': 97,\n",
              " 'eek': 7,\n",
              " 'ek.': 2,\n",
              " 'iso': 41,\n",
              " 'sol': 26,\n",
              " 'ola': 6,\n",
              " 'lat': 47,\n",
              " 'ati': 165,\n",
              " 'tio': 231,\n",
              " 'ion': 304,\n",
              " 'on.': 479,\n",
              " '.ou': 110,\n",
              " 'cou': 73,\n",
              " 'se.': 285,\n",
              " '.ca': 378,\n",
              " 'can': 216,\n",
              " 'an.': 376,\n",
              " '.on': 324,\n",
              " 'onl': 65,\n",
              " 'nly': 71,\n",
              " '.sa': 181,\n",
              " 'say': 33,\n",
              " 'aba': 12,\n",
              " 'ban': 29,\n",
              " 'and': 908,\n",
              " 'ndo': 12,\n",
              " 'one': 261,\n",
              " 'ned': 96,\n",
              " '.ci': 27,\n",
              " 'cit': 27,\n",
              " 'ity': 179,\n",
              " 'ty.': 204,\n",
              " 'whe': 122,\n",
              " 'hen': 126,\n",
              " 'en.': 335,\n",
              " 'ady': 58,\n",
              " 'dy.': 81,\n",
              " 'lak': 17,\n",
              " '.su': 197,\n",
              " 'umm': 15,\n",
              " 'mmo': 22,\n",
              " 'mon': 138,\n",
              " 'rve': 36,\n",
              " 'get': 111,\n",
              " 'et.': 191,\n",
              " '.bo': 114,\n",
              " 'bor': 25,\n",
              " 'int': 129,\n",
              " 'nte': 120,\n",
              " 'tel': 84,\n",
              " 'lli': 43,\n",
              " 'lig': 37,\n",
              " 'ige': 16,\n",
              " 'gen': 41,\n",
              " '.pe': 134,\n",
              " 'peo': 67,\n",
              " 'eop': 67,\n",
              " 'opl': 70,\n",
              " 'ple': 125,\n",
              " 'le.': 301,\n",
              " '.ne': 192,\n",
              " 'nev': 15,\n",
              " 'eve': 187,\n",
              " 'ver': 250,\n",
              " '.an': 945,\n",
              " 'nd.': 997,\n",
              " '.br': 86,\n",
              " 'bro': 26,\n",
              " 'rou': 109,\n",
              " 'lib': 2,\n",
              " 'ibr': 5,\n",
              " 'bra': 22,\n",
              " 'rar': 23,\n",
              " 'ary': 22,\n",
              " 'ry.': 179,\n",
              " 'wen': 11,\n",
              " 'nto': 50,\n",
              " '.ex': 93,\n",
              " 'exi': 5,\n",
              " 'xil': 4,\n",
              " 'ile': 42,\n",
              " '.us': 99,\n",
              " 'use': 140,\n",
              " '.kn': 256,\n",
              " 'kno': 239,\n",
              " 'owl': 27,\n",
              " 'wle': 25,\n",
              " 'edg': 29,\n",
              " 'dge': 34,\n",
              " 'ge.': 109,\n",
              " '.dr': 75,\n",
              " 'dra': 80,\n",
              " 'raw': 12,\n",
              " 'aw.': 24,\n",
              " '.fr': 142,\n",
              " 'fro': 96,\n",
              " 'rom': 106,\n",
              " 'om.': 110,\n",
              " 'boo': 26,\n",
              " 'ook': 67,\n",
              " 'oks': 19,\n",
              " 'ks.': 76,\n",
              " 'erb': 10,\n",
              " 'rbs': 4,\n",
              " 'bs.': 12,\n",
              " '.pr': 214,\n",
              " 'pre': 74,\n",
              " 'rep': 28,\n",
              " 'epa': 13,\n",
              " 'par': 41,\n",
              " '.po': 148,\n",
              " 'pot': 8,\n",
              " 'oti': 22,\n",
              " 'ons': 176,\n",
              " 'ns.': 211,\n",
              " '.mu': 93,\n",
              " 'mur': 6,\n",
              " 'urk': 4,\n",
              " 'rky': 2,\n",
              " 'ky.': 15,\n",
              " 'wat': 29,\n",
              " 'ter': 329,\n",
              " 'ers': 262,\n",
              " 'rs.': 280,\n",
              " 'pro': 132,\n",
              " 'rov': 28,\n",
              " 'ovi': 12,\n",
              " 'vid': 16,\n",
              " 'ide': 169,\n",
              " 'de.': 68,\n",
              " 'foo': 14,\n",
              " 'ood': 86,\n",
              " 'od.': 76,\n",
              " 'in.': 499,\n",
              " 'exc': 17,\n",
              " 'xch': 3,\n",
              " 'cha': 86,\n",
              " 'ang': 60,\n",
              " 'nge': 81,\n",
              " 'ur.': 224,\n",
              " '.pl': 98,\n",
              " 'eas': 114,\n",
              " 'ase': 48,\n",
              " 'exa': 15,\n",
              " 'xam': 7,\n",
              " 'ami': 20,\n",
              " 'min': 78,\n",
              " 'ine': 83,\n",
              " 'ne.': 212,\n",
              " '.ye': 83,\n",
              " 'yea': 15,\n",
              " 'ear': 212,\n",
              " 'ars': 32,\n",
              " 'oli': 22,\n",
              " 'lit': 99,\n",
              " 'itu': 10,\n",
              " 'tud': 15,\n",
              " 'ude': 17,\n",
              " '.al': 327,\n",
              " 'llo': 26,\n",
              " 'low': 58,\n",
              " 'owe': 95,\n",
              " 'wed': 19,\n",
              " 'cop': 6,\n",
              " 'opy': 2,\n",
              " 'py.': 8,\n",
              " 'man': 197,\n",
              " 'any': 111,\n",
              " 'ny.': 85,\n",
              " 'mes': 47,\n",
              " '.ov': 40,\n",
              " 'ove': 109,\n",
              " 'con': 150,\n",
              " 'ten': 86,\n",
              " 'hes': 92,\n",
              " 'ese': 56,\n",
              " 'opi': 6,\n",
              " 'pie': 12,\n",
              " 'wer': 159,\n",
              " 'meo': 16,\n",
              " 'eon': 19,\n",
              " 'eem': 17,\n",
              " 'em.': 200,\n",
              " 'com': 154,\n",
              " 'omf': 1,\n",
              " 'mfo': 1,\n",
              " 'ort': 88,\n",
              " 'rta': 42,\n",
              " 'tab': 14,\n",
              " 'abl': 65,\n",
              " 'ble': 148,\n",
              " '.ot': 60,\n",
              " 'oth': 124,\n",
              " '.qu': 77,\n",
              " 'que': 53,\n",
              " 'ues': 32,\n",
              " 'sti': 109,\n",
              " 'nyt': 26,\n",
              " 'yth': 47,\n",
              " 'ind': 125,\n",
              " 'rob': 34,\n",
              " 'obl': 29,\n",
              " 'lem': 72,\n",
              " 'not': 204,\n",
              " 'ot.': 207,\n",
              " 'how': 103,\n",
              " 'olv': 20,\n",
              " 'lve': 66,\n",
              " 'hel': 80,\n",
              " 'elp': 68,\n",
              " 'lp.': 60,\n",
              " 'nea': 32,\n",
              " 'arb': 4,\n",
              " 'rby': 1,\n",
              " 'dru': 8,\n",
              " 'rui': 11,\n",
              " 'uid': 10,\n",
              " 'ids': 7,\n",
              " '.ri': 93,\n",
              " 'rin': 97,\n",
              " 'anc': 74,\n",
              " 'nci': 65,\n",
              " 'cie': 12,\n",
              " 'ien': 47,\n",
              " '.st': 276,\n",
              " 'sta': 128,\n",
              " 'tat': 38,\n",
              " 'atu': 65,\n",
              " 'tue': 5,\n",
              " 'ue.': 46,\n",
              " 'odd': 12,\n",
              " 'dde': 24,\n",
              " 'des': 86,\n",
              " 'pla': 89,\n",
              " 'lac': 55,\n",
              " 'ace': 79,\n",
              " 'ce.': 312,\n",
              " 'sat': 15,\n",
              " 'tur': 148,\n",
              " 'ura': 23,\n",
              " 'rat': 54,\n",
              " 'pow': 43,\n",
              " 'aws': 7,\n",
              " 'ws.': 30,\n",
              " '.da': 116,\n",
              " 'dan': 48,\n",
              " 'ero': 17,\n",
              " 'ous': 104,\n",
              " 'us.': 99,\n",
              " '.en': 120,\n",
              " 'nti': 93,\n",
              " 'tit': 17,\n",
              " 'iti': 83,\n",
              " 'tie': 27,\n",
              " '.un': 123,\n",
              " 'unc': 24,\n",
              " 'nco': 16,\n",
              " 'omm': 32,\n",
              " 'wil': 116,\n",
              " 'ild': 41,\n",
              " '.hu': 99,\n",
              " 'hun': 50,\n",
              " 'unt': 78,\n",
              " 'beg': 5,\n",
              " 'ega': 14,\n",
              " 'gan': 21,\n",
              " 'hau': 9,\n",
              " 'aun': 8,\n",
              " 'cir': 8,\n",
              " 'irc': 8,\n",
              " 'rcl': 7,\n",
              " 'cle': 36,\n",
              " '.re': 327,\n",
              " 'ece': 29,\n",
              " 'cen': 42,\n",
              " 'ntl': 19,\n",
              " 'tly': 43,\n",
              " 'its': 112,\n",
              " 'ts.': 507,\n",
              " 'hop': 18,\n",
              " 'pin': 20,\n",
              " 'uls': 22,\n",
              " 'ls.': 83,\n",
              " 'arr': 46,\n",
              " 'rri': 43,\n",
              " 'rio': 42,\n",
              " 'ior': 23,\n",
              " 'ors': 54,\n",
              " 'lai': 26,\n",
              " 'aid': 44,\n",
              " 'id.': 128,\n",
              " '.ku': 5,\n",
              " 'kur': 5,\n",
              " 'urg': 8,\n",
              " 'rga': 16,\n",
              " 'ans': 68,\n",
              " 'hut': 9,\n",
              " '.de': 285,\n",
              " 'dea': 96,\n",
              " 'eal': 69,\n",
              " 'lik': 69,\n",
              " 'ike': 75,\n",
              " 'wan': 60,\n",
              " 'ant': 221,\n",
              " 'kil': 52,\n",
              " '.9.': 2,\n",
              " '.ph': 21,\n",
              " 'pha': 8,\n",
              " 'tom': 26,\n",
              " 'oms': 8,\n",
              " 'ms.': 50,\n",
              " 'hal': 48,\n",
              " '.nu': 10,\n",
              " 'num': 10,\n",
              " 'umb': 9,\n",
              " 'mbe': 30,\n",
              " 'ber': 55,\n",
              " 'per': 92,\n",
              " 'erh': 12,\n",
              " 'rha': 6,\n",
              " 'hap': 36,\n",
              " 'aps': 7,\n",
              " 'ps.': 35,\n",
              " '.ap': 43,\n",
              " 'app': 78,\n",
              " 'ppe': 71,\n",
              " 'ara': 39,\n",
              " 'ran': 63,\n",
              " 'nce': 223,\n",
              " 'dri': 14,\n",
              " 'riv': 13,\n",
              " 'ive': 240,\n",
              " 'off': 36,\n",
              " 'ff.': 34,\n",
              " 'rew': 36,\n",
              " 'ewa': 13,\n",
              " 'may': 43,\n",
              " 'ok.': 29,\n",
              " '.va': 30,\n",
              " 'vam': 17,\n",
              " 'amp': 58,\n",
              " 'mpi': 20,\n",
              " 'res': 282,\n",
              " '.ow': 19,\n",
              " 'own': 113,\n",
              " 'wne': 24,\n",
              " 'ner': 49,\n",
              " 'rsh': 10,\n",
              " 'shi': 23,\n",
              " 'hip': 9,\n",
              " 'ip.': 8,\n",
              " 'uts': 13,\n",
              " '.wr': 23,\n",
              " 'wre': 5,\n",
              " 'rea': 189,\n",
              " 'eat': 163,\n",
              " 'ath': 66,\n",
              " 'org': 36,\n",
              " 'rge': 18,\n",
              " 'etm': 3,\n",
              " 'tme': 6,\n",
              " 'men': 108,\n",
              " 'eno': 41,\n",
              " 'ots': 20,\n",
              " 'rem': 46,\n",
              " 'eme': 87,\n",
              " 'mem': 42,\n",
              " 'emb': 44,\n",
              " 'his': 217,\n",
              " 'erf': 37,\n",
              " 'rfu': 20,\n",
              " 'ful': 68,\n",
              " 'ul.': 62,\n",
              " '.op': 54,\n",
              " 'opp': 42,\n",
              " 'ppo': 57,\n",
              " 'pon': 63,\n",
              " 'nen': 44,\n",
              " 'no.': 102,\n",
              " 'tal': 96,\n",
              " 'al.': 178,\n",
              " '.ev': 98,\n",
              " 'ven': 99,\n",
              " 'ope': 37,\n",
              " 'pe.': 17,\n",
              " 'def': 21,\n",
              " 'efe': 21,\n",
              " 'fea': 28,\n",
              " '.hi': 249,\n",
              " 'him': 111,\n",
              " 'im.': 213,\n",
              " 'so.': 110,\n",
              " 'fig': 43,\n",
              " 'igh': 214,\n",
              " 'ndr': 71,\n",
              " 'rak': 4,\n",
              " '.ro': 48,\n",
              " 'roo': 21,\n",
              " 'oot': 8,\n",
              " 'ar.': 145,\n",
              " 'mag': 73,\n",
              " 'agi': 56,\n",
              " 'gic': 47,\n",
              " 'ic.': 63,\n",
              " 'rb.': 4,\n",
              " '.ke': 33,\n",
              " 'kee': 18,\n",
              " 'eep': 23,\n",
              " 'ep.': 16,\n",
              " '.ba': 125,\n",
              " 'bay': 1,\n",
              " 'mer': 47,\n",
              " 'rel': 44,\n",
              " 'ely': 75,\n",
              " 'ndl': 14,\n",
              " 'dle': 17,\n",
              " 'tan': 106,\n",
              " 'nds': 56,\n",
              " 'spr': 2,\n",
              " 'pri': 51,\n",
              " 'ink': 82,\n",
              " 'nkl': 1,\n",
              " 'kle': 1,\n",
              " '.up': 35,\n",
              " 'upo': 1,\n",
              " '.fl': 40,\n",
              " 'fla': 14,\n",
              " 'lam': 90,\n",
              " 'oun': 136,\n",
              " 'und': 177,\n",
              " 'lpf': 2,\n",
              " 'pfu': 2,\n",
              " '.il': 100,\n",
              " 'emi': 55,\n",
              " 'was': 105,\n",
              " '.sl': 28,\n",
              " 'sla': 13,\n",
              " 'lay': 18,\n",
              " 'hey': 250,\n",
              " 'ey.': 273,\n",
              " '.ni': 29,\n",
              " 'nig': 40,\n",
              " 'fie': 23,\n",
              " 'ier': 18,\n",
              " 'erc': 22,\n",
              " 'rce': 48,\n",
              " 'ces': 79,\n",
              " 'hem': 192,\n",
              " 'did': 65,\n",
              " '.jo': 13,\n",
              " 'job': 10,\n",
              " 'ob.': 13,\n",
              " 'gon': 26,\n",
              " 'spl': 7,\n",
              " 'len': 30,\n",
              " 'end': 114,\n",
              " 'ndi': 53,\n",
              " '.am': 62,\n",
              " 'am.': 36,\n",
              " 'gra': 75,\n",
              " 'tef': 6,\n",
              " 'efu': 24,\n",
              " 'whi': 63,\n",
              " 'hic': 47,\n",
              " 'ich': 42,\n",
              " 'ch.': 128,\n",
              " 'riz': 11,\n",
              " 'ize': 24,\n",
              " 'ze.': 25,\n",
              " '.ta': 133,\n",
              " 'tak': 62,\n",
              " 'als': 43,\n",
              " 'lso': 25,\n",
              " 'sac': 10,\n",
              " 'ack': 83,\n",
              " 'ck.': 161,\n",
              " 'hol': 33,\n",
              " 'oly': 8,\n",
              " 'sal': 78,\n",
              " 'car': 56,\n",
              " 'rry': 23,\n",
              " 'fen': 22,\n",
              " 'mig': 31,\n",
              " 'sef': 2,\n",
              " '.im': 189,\n",
              " 'ste': 213,\n",
              " 'key': 13,\n",
              " 'doo': 4,\n",
              " 'oor': 8,\n",
              " 'ref': 29,\n",
              " 'ull': 53,\n",
              " 'mom': 8,\n",
              " 'rig': 77,\n",
              " '.te': 91,\n",
              " '.ag': 75,\n",
              " 'aga': 29,\n",
              " 'gai': 54,\n",
              " 'ain': 178,\n",
              " 'rds': 38,\n",
              " 'nta': 26,\n",
              " 'tai': 32,\n",
              " 'alp': 8,\n",
              " 'lps': 9,\n",
              " 'bru': 8,\n",
              " 'rux': 7,\n",
              " 'uxa': 7,\n",
              " 'xae': 1,\n",
              " 'ae.': 1,\n",
              " 'fle': 18,\n",
              " 'edd': 8,\n",
              " 'der': 156,\n",
              " '.ga': 37,\n",
              " 'gar': 34,\n",
              " 'ark': 30,\n",
              " 'rki': 19,\n",
              " '.if': 92,\n",
              " 'if.': 93,\n",
              " '.ch': 119,\n",
              " 'cho': 27,\n",
              " 'hoo': 14,\n",
              " 'oos': 13,\n",
              " 'ose': 82,\n",
              " 'san': 16,\n",
              " 'nct': 17,\n",
              " 'ctu': 23,\n",
              " 'tua': 14,\n",
              " 'uar': 48,\n",
              " 'sto': 76,\n",
              " 'tor': 50,\n",
              " 'nee': 83,\n",
              " 'eed': 112,\n",
              " '.gh': 26,\n",
              " 'gho': 29,\n",
              " 'hos': 53,\n",
              " 'ret': 65,\n",
              " 'etu': 18,\n",
              " 'urn': 52,\n",
              " 'rn.': 70,\n",
              " 'alm': 11,\n",
              " 'lm.': 2,\n",
              " 'pec': 80,\n",
              " 'eci': 61,\n",
              " 'cif': 11,\n",
              " 'ifi': 24,\n",
              " 'fic': 31,\n",
              " 'ali': 90,\n",
              " 'lin': 123,\n",
              " 'na.': 46,\n",
              " '.sh': 212,\n",
              " 'she': 95,\n",
              " '.tu': 29,\n",
              " 'rne': 33,\n",
              " '.tr': 168,\n",
              " 'try': 50,\n",
              " 'ryi': 9,\n",
              " 'yin': 31,\n",
              " 'pos': 48,\n",
              " 'oss': 22,\n",
              " 'sse': 31,\n",
              " 'ses': 62,\n",
              " 'ssi': 57,\n",
              " 'sio': 43,\n",
              " '.ra': 76,\n",
              " 'ite': 45,\n",
              " 'tem': 101,\n",
              " 'neh': 14,\n",
              " 'eha': 13,\n",
              " 'ale': 53,\n",
              " 'enn': 10,\n",
              " 'nni': 26,\n",
              " 'nia': 9,\n",
              " 'ias': 4,\n",
              " 'mir': 31,\n",
              " 'irr': 29,\n",
              " 'rro': 47,\n",
              " 'ror': 29,\n",
              " 'oft': 14,\n",
              " 'fte': 45,\n",
              " 'ved': 73,\n",
              " 'rop': 25,\n",
              " 'oph': 14,\n",
              " 'phe': 23,\n",
              " 'het': 10,\n",
              " 'ets': 49,\n",
              " 'ora': 13,\n",
              " 'rac': 55,\n",
              " 'acl': 8,\n",
              " '.ac': 61,\n",
              " 'acc': 26,\n",
              " 'ccu': 14,\n",
              " 'cur': 42,\n",
              " 'tho': 90,\n",
              " 'hou': 142,\n",
              " 'gh.': 72,\n",
              " 'onf': 17,\n",
              " 'nfu': 12,\n",
              " 'fus': 7,\n",
              " 'usi': 54,\n",
              " 'sin': 90,\n",
              " 'ngl': 13,\n",
              " 'gly': 11,\n",
              " 'eto': 4,\n",
              " 'tol': 13,\n",
              " 'old': 56,\n",
              " '.fu': 53,\n",
              " 'fut': 14,\n",
              " 'utu': 11,\n",
              " 'ure': 228,\n",
              " '.ad': 38,\n",
              " 'adv': 15,\n",
              " 'dvi': 8,\n",
              " 'vic': 38,\n",
              " 'ice': 76,\n",
              " 'ski': 18,\n",
              " 'usu': 15,\n",
              " 'sua': 16,\n",
              " 'ual': 32,\n",
              " 'quo': 33,\n",
              " 'uot': 32,\n",
              " 'otw': 4,\n",
              " 'twh': 4,\n",
              " '.fa': 109,\n",
              " 'fai': 16,\n",
              " 'air': 22,\n",
              " 'llq': 3,\n",
              " 'lqu': 4,\n",
              " 'dis': 60,\n",
              " 'ist': 86,\n",
              " 'ngu': 9,\n",
              " 'gui': 11,\n",
              " 'uis': 7,\n",
              " 'ish': 43,\n",
              " 'hed': 24,\n",
              " 'urt': 15,\n",
              " 'rte': 17,\n",
              " 'teo': 2,\n",
              " 'eou': 5,\n",
              " '.sm': 14,\n",
              " 'sma': 14,\n",
              " 'mas': 29,\n",
              " 'ash': 15,\n",
              " 'cis': 13,\n",
              " 'ise': 48,\n",
              " 'nas': 31,\n",
              " '.pa': 108,\n",
              " 'art': 60,\n",
              " 'rts': 18,\n",
              " 'sem': 10,\n",
              " 'mbl': 8,\n",
              " 'gav': 5,\n",
              " '.ef': 26,\n",
              " 'eff': 26,\n",
              " 'ffe': 57,\n",
              " 'fec': 35,\n",
              " '.ce': 46,\n",
              " 'cea': 8,\n",
              " 'sed': 71,\n",
              " 'att': 102,\n",
              " 'tta': 45,\n",
              " 'tac': 101,\n",
              " 'cki': 30,\n",
              " 'ems': 24,\n",
              " 'nde': 144,\n",
              " 'rst': 58,\n",
              " 'too': 38,\n",
              " 'til': 32,\n",
              " 'doe': 18,\n",
              " 'oes': 22,\n",
              " 'bel': 43,\n",
              " 'eli': 107,\n",
              " 'lie': 47,\n",
              " 'iev': 31,\n",
              " 'wn.': 76,\n",
              " 'nts': 117,\n",
              " 'ddi': 15,\n",
              " 'din': 77,\n",
              " 'mus': 40,\n",
              " 'ust': 103,\n",
              " '.lo': 134,\n",
              " 'loc': 11,\n",
              " 'oca': 5,\n",
              " 'cal': 83,\n",
              " 'soo': 21,\n",
              " 'ths': 8,\n",
              " 'hsa': 2,\n",
              " 'aye': 6,\n",
              " 'yer': 4,\n",
              " 'nks': 25,\n",
              " 'far': 20,\n",
              " 'ewe': 19,\n",
              " 'yes': 48,\n",
              " 'ben': 5,\n",
              " 'ene': 69,\n",
              " 'saw': 9,\n",
              " 'bef': 19,\n",
              " 'efo': 22,\n",
              " 'ita': 30,\n",
              " 'tag': 11,\n",
              " 'omb': 40,\n",
              " 'mbs': 5,\n",
              " 'kni': 12,\n",
              " 'hts': 15,\n",
              " 'ied': 30,\n",
              " 'ges': 27,\n",
              " 'ava': 2,\n",
              " 'van': 12,\n",
              " 'ded': 60,\n",
              " 'hon': 4,\n",
              " 'ono': 4,\n",
              " 'nor': 22,\n",
              " 'nst': 83,\n",
              " '.bl': 86,\n",
              " 'bla': 11,\n",
              " '.sk': 24,\n",
              " 'sku': 7,\n",
              " 'kul': 9,\n",
              " '.el': 64,\n",
              " 'lle': 83,\n",
              " 'lev': 17,\n",
              " 'rer': 12,\n",
              " 'eri': 89,\n",
              " 'ris': 42,\n",
              " 'lta': 6,\n",
              " 'tar': 30,\n",
              " 'hti': 11,\n",
              " 'bea': 44,\n",
              " 'ast': 119,\n",
              " 'rss': 1,\n",
              " 'mb.': 21,\n",
              " '.sy': 9,\n",
              " 'sym': 8,\n",
              " 'ymb': 9,\n",
              " 'mbo': 13,\n",
              " 'bol': 15,\n",
              " 'lic': 52,\n",
              " 'los': 34,\n",
              " 'mis': 51,\n",
              " 'iss': 38,\n",
              " 'las': 18,\n",
              " 'rey': 3,\n",
              " 'eyn': 1,\n",
              " 'yna': 1,\n",
              " 'nar': 10,\n",
              " 'ord': 70,\n",
              " 'rdi': 13,\n",
              " 'inn': 20,\n",
              " 'nnk': 1,\n",
              " 'nke': 5,\n",
              " 'epe': 3,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CREATING A MODEL"
      ],
      "metadata": {
        "id": "iUYL2kf6h-x1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A smaller angle between the language vector and the vector made from the given text implies greater similarity. To get the angle we compute cosine of the angle between the vectors. Since greater cosine means smaller angle, we directly use the cosine as the score for a given language. Language with the maximum score is the predicted language."
      ],
      "metadata": {
        "id": "Ru5dmctIU_ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cosine_model:\n",
        "  def __init__(self):\n",
        "    # initializing language to trigram counts\n",
        "    self.lang_trigram = {}\n",
        "\n",
        "  # train model (create trigram vector for given language)\n",
        "  def train(self, language, preprocessed_data):\n",
        "    self.lang_trigram[language] = create_trigram_vector(preprocessed_data)\n",
        "\n",
        "  # function to return vector length given trigram counts\n",
        "  def vec_length(self, trigram_count):\n",
        "    sum = 0\n",
        "    for key, value in trigram_count.items():\n",
        "      sum += value*value\n",
        "    length = math.sqrt(sum)\n",
        "    return length\n",
        "\n",
        "  # function return cosine of language vector and text trigram vector\n",
        "  def cosine(self, language, text_trigram_vec):\n",
        "    dot = 0.0\n",
        "    # for given language look up the trigram vector\n",
        "    lang_count = self.lang_trigram[language]\n",
        "    # calculating dot product\n",
        "    for key, value in text_trigram_vec.items():\n",
        "      if key in lang_count:\n",
        "        dot += (value * lang_count[key])\n",
        "    # calculating cosine using dot product of the vectors and their lengths\n",
        "    cosine = dot / (self.vec_length(lang_count) * self.vec_length(text_trigram_vec))\n",
        "    return cosine\n",
        "\n",
        "  # predicting language for text given\n",
        "  def predict(self, text):\n",
        "    trigram_text = create_trigram_vector(text)\n",
        "    result = {}\n",
        "    for key, value in self.lang_trigram.items():\n",
        "      result[key] = self.cosine(key, trigram_text)\n",
        "        \n",
        "    result = sorted(result.items(), key = lambda x: -x[1])\n",
        "    if result[0][1] == 0.0:\n",
        "      print('\\ncannot detect language')\n",
        "    else:\n",
        "      print('\\nlanguage of given text document is most likely to be: ', result[0][0])\n",
        "    return result[0][0]\n"
      ],
      "metadata": {
        "id": "otw5OJ-5cKbn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING OUT THE MODEL"
      ],
      "metadata": {
        "id": "qfIsDLD70AB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "training the model"
      ],
      "metadata": {
        "id": "s4-xhi3Y0Eix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = cosine_model()\n",
        "m.train('English', preprocess_data(load_training_data('English')))\n",
        "m.train('French', preprocess_data(load_training_data('French')))\n",
        "m.train('Czech', preprocess_data(load_training_data('Czech')))\n",
        "m.train('German', preprocess_data(load_training_data('German')))\n",
        "m.train('Hungarian', preprocess_data(load_training_data('Hungarian')))\n",
        "m.train('Italian', preprocess_data(load_training_data('Italian')))\n",
        "m.train('Polish', preprocess_data(load_training_data('Polish')))\n",
        "m.train('Russian', preprocess_data(load_training_data('Russian')))\n",
        "m.train('Spanish', preprocess_data(load_training_data('Spanish')))"
      ],
      "metadata": {
        "id": "sptxLu48jLpE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with an english paragraph"
      ],
      "metadata": {
        "id": "R9vuT0F00WAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'English'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzmhQtfOsu5m",
        "outputId": "5e42c893-2d8a-4994-d2c1-46c8a0077a8b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Along with the smooth flow of sentences, a paragraphs coherence may also be related to its length. If you have written a very long paragraph, one that fills a double-spaced typed page, for example, you should check it carefully to see if it should start a new paragraph where the original paragraph wanders from its controlling idea. On the other hand, if a paragraph is very short (only one or two sentences, perhaps), you may need to develop its controlling idea more thoroughly, or combine it with another paragraph.\n",
            "\n",
            "language of given text document is most likely to be:  English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a french paragraph"
      ],
      "metadata": {
        "id": "dxv20ifZ1AVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'French'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad83bc7-b259-4098-ab49-4f8606078c2b",
        "id": "qBsK5RZ-1AVI"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Je mappelle Jessica. Je suis une fille, je suis franaise et jai treize ans. Je vais  lcole  Nice, mais jhabite  Cagnes-Sur-Mer. Jai deux frres. Le premier sappelle Thomas, il a quatorze ans. Le second sappelle Yann et il a neuf ans. Mon papa est italien et il est fleuriste. Ma mre est allemande et est avocate. Mes frres et moi parlons franais, italien et allemand  la maison. Nous avons une grande maison avec un chien, un poisson et deux chats.\n",
            "\n",
            "language of given text document is most likely to be:  French\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a czech paragraph"
      ],
      "metadata": {
        "id": "2i41gP091XMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Czech'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe2538b-e18a-4b1f-fa29-fa8fd178283f",
        "id": "ZoNuUeSu1XMO"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Pan Novk stoj na ndra a vyhl svj vlak. U tu ml dvno bt, asi m zpodn, k si. Dnes jede na pracovn schzku do Brna. V Brn se mu lb. Je to krsn msto a stle se tam nco dje: vstavy, festivaly, koncerty, maj tam dobr restaurace a hezkou produ. koda jen, e se tam v centru patn parkuje.\n",
            "\n",
            "language of given text document is most likely to be:  Czech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a german paragraph"
      ],
      "metadata": {
        "id": "mxP54AUb1mSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'German'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115c4535-e859-42e0-801e-8e6527e2d623",
        "id": "YmvKjRQu1mS0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Familie Mller plant ihren Urlaub. Sie geht in ein Reisebro und lsst sich von einem Angestellten beraten. Als Reiseziel whlt sie Mallorca aus. Familie Mller bucht einen Flug auf die Mittelmeerinsel. Sie bucht auerdem zwei Zimmer in einem groen Hotel direkt am Strand. Familie Mller badet gerne im Meer.\n",
            "\n",
            "language of given text document is most likely to be:  German\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with an hungarian paragraph"
      ],
      "metadata": {
        "id": "fx398_pJ1x23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Hungarian'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c76a7c8-fa51-4240-cef6-02e3eb8a3859",
        "id": "nU7ap00M1x24"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: A nevelsnek az emberi szemlyisg teljes kibontakoztatsra, valamint az emberi jogok s alapvet szabadsgok tiszteletbentartsnak megerstsre kell irnyulnia. A nevelsnek el kell segtenie a nemzetek, valamint az sszes faji s vallsi csoportok kztti megrtst, trelmet s bartsgot, valamint az Egyeslt Nemzetek ltal a bke fenntartsnak rdekben kifejtett tevkenysg kifejldst. 3) A szlket elsbbsgi jog illeti meg a gyermekeiknek adand nevels megvlasztsban.\n",
            "\n",
            "language of given text document is most likely to be:  Hungarian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with an italian paragraph"
      ],
      "metadata": {
        "id": "8zkuLxJT2EZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Italian'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09aab242-3073-4db5-b79a-e588b74df0a3",
        "id": "XQ1KhjOt2EZc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: La nostra famiglia  composta anche da altre due persone, i nostri figli, Manuela che ha diciassette anni, e Marco che ha quindici anni, e poi c' anche Tremendo, il cane che vive con noi da nove anni, ed  parte della famiglia. Viviamo tutti nella nostra splendida casa con un grande giardino.\n",
            "\n",
            "language of given text document is most likely to be:  Italian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a polish paragraph"
      ],
      "metadata": {
        "id": "n3-X3Bee2ULU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Polish'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803b1f27-01a9-4261-ac99-87d484f8da18",
        "id": "0GNmvF622ULV"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Kadego roku Mateusz nie moe si doczeka tego dnia. Ju wiele tygodni przed t dat starannie planuje cae przyjcie. Zaczyna od wyboru listy goci. Nie mona oczywicie zapomnie o rodzinie. Dlatego zawsze mile widziani s: mama, tata, brat oraz siostra. Czasem udaje si te zaprosi babci, jeeli dobrze si czuje. Przecie im wicej goci tym lepiej - nie tylko ze wzgldu na prezenty. Oprcz goci bdcych osobami z jego rodziny, Mateusz nigdy nie zapomina te o swoich kolegach i przyjacioach. Co to byyby za urodziny, na ktrych nie pojawiby si Kacper, Ola, Wojtek albo Dawid?\n",
            "\n",
            "language of given text document is most likely to be:  Polish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a russian paragraph"
      ],
      "metadata": {
        "id": "-SWgfKgR2m9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Russian'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315c6f80-d954-4f06-b415-515b2216a9ec",
        "id": "iur5CQyT2m9j"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language:      ,     .    ,     .      .        .      ,   .    ,      .         .       \n",
            "\n",
            "language of given text document is most likely to be:  Russian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing with a spanish paragraph"
      ],
      "metadata": {
        "id": "F7S_7yXU21dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [input(\"enter a paragraph to detect language: \")]\n",
        "test_clean = preprocess_data(test)\n",
        "language = m.predict(test_clean)\n",
        "assert language == 'Spanish'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab049b1-050b-4b12-b97f-4433d64dfd0b",
        "id": "x_shx40F21dS"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a paragraph to detect language: Hoy hace mucho fro. Es invierno y todas las calles estn cubiertas de nieve. Dentro de poco vendr la primavera y con ella el sol y el tiempo clido. La semana pasada estuvo de lluvia y tormenta. Incluso un rayo cay encima de la campana de la catedral, pero no ocurri nada. Los truenos siempre me han dado miedo y mucho respeto. Pero tenemos suerte... pues la previsin del tiempo para maana es muy buena. Dicen que hoy habr heladas y por la tarde granizo, pero maana el da ser soleado. A ver si tengo suerte y veo algn arcoris.\n",
            "\n",
            "language of given text document is most likely to be:  Spanish\n"
          ]
        }
      ]
    }
  ]
}